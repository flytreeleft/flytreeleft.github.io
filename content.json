{"pages":[{"title":"About me","permalink":"https://flytreeleft.github.io/about/index.html","text":"个人展示 个人站点： https://flytreeleft.org、 https://flytreeleft.github.io Github： https://github.com/flytreeleft Twitter: https://twitter.com/flytreeleft Email： flytreeleft@126.com 自我评价 踏实肯干，具有较硬的技术基础。密切关注前沿技术，不断学习以充实自我 学以致用，在架构设计和研发过程中推陈出新，适当引入新的技术和设计理念 勤于思考，不固化观念，保持一颗年轻的心 善于解决问题，打破砂锅问到底，先分析问题本质，再有针对性地提出多种解决方案，权衡并选择最优的解决方案 专业技能 从事8年Java项目开发，具备J2EE项目开发、项目架构设计、代码优化与调试经验 熟悉Web前端和后端开发流程及相关技术：Spring、Spring MVC、Hibernate、MyBatis、jQuery、Vue.js、Node.js、Webpack、Electron、TypeScript、ES6等 熟悉MySQL、H2、Oracle等关系数据库，可熟练编写SQL代码进行简单或复杂的业务查询，具备MySQL主从架构部署经验 具备JVM调试与调优经验，能够通过jstack、jmap、Eclipse Memory Analyzer等工具定位堆栈溢出、线程死锁等问题 能够熟练编写JUnit单元测试，并具备Apache JMeter性能测试和脚本编写经验 具备良好的技术文档编写能力，对代码质量和规范的要求严格，同时乐于以文档形式与他人分享技术难点攻关技巧 熟悉Linux系统运维，能够熟练编写Bash、Ansible Playbooks等脚本，也具备一定的Python、Lua等编程基础 具备CI/CD、DevOps工具集的部署、维护和管理经验：Gitlab、Jenkins、Nexus3、Nginx、Sonar、MediaWiki、Keycloak、Rocket.Chat、ELK、Grafana等 具备Kubernetes高可用集群的部署和维护经验，能够在Kubernetes集群中部署、配置和管理各种应用，熟悉Helm的使用 开源项目nexus3-keycloak-plugin支持Keycloak用户统一认证的Sonatype Nexus3插件。 其支持并提供如下特性： 将Keycloak的Client Role、Realm Role、Realm Group三类角色/组映射为Nexus3的角色，以支持不同层级的用户权限控制需求 支持多个Keycloak Realm（至多4个），从而满足组织同时对内部和外部用户（两类用户隔离在不同的Realm中）的访问控制需求 在Nginx反向代理的配合下实现基于Keycloak的单点登录（SSO）和二次登录验证 docker-nginx-gatewayNginx网关（反向代理）的Docker镜像构建脚本。 其提供特性如下： 可启用Let’s Encrypt HTTPS站点 支持通过certbot自动为域名创建和更新Let’s Encrypt证书 支持显示自定义的错误（500、404等）页面，且在有多个错误页面时能够做到随机展示 可加载并执行Lua脚本 支持反向代理HTTP和TCP流量 每个域名采用独立的配置文件，根据实际需求以提供静态站点服务或反向代理至后端服务 支持在Kubernetes中以多个Pod副本运行 支持访问日志按天滚动写入日志文件，如，access_2018-04-26.log 支持通过OpenID（使用lua-resty-openidc实现）进行用户访问认证，并可将指定IP加入白名单 可在构建镜像时设定是否引入GeoIp2地址库 集成Gixy以分析和检查Nginx配置是否存在安全问题 GtkShot基于GTK2的Linux屏幕截图工具。 其具备如下特性： 支持快捷键撤销、保存、移动选取等操作 支持线、框、圈、文字等涂鸦 可保存截图至剪贴板或文件 提供友好的选区位置/大小、初始时的界面操作等辅助提示（支持中英文双语） 其他向多个开源项目提交PR，贡献缺陷修复、功能改进、新增功能、文档修正等： ansible/ansible：对vmware_*相关模块的改进和缺陷修复（长期未被接受，导致修复代码过期，已关闭） kubernetes/website：提交对文档中有关MySQL主从配置示例中的错误修复和相关改进（已合并） webpack-contrib/webpack-hot-middleware：缺陷修复和功能改进（已合并） Semantic-Org/Semantic-UI：改进和完善Slider组件（已合并，但似乎未进入主干） erikw/tmux-powerline：提供基于Yahoo天气的模块，并改进和修复其他多个模块（已合并） docker-library/mysql：提交MySQL初始账号授权不生效的修复（未合并） vuejs/vue：提交缺陷修复代码，改进构建脚本等（已合并） Activiti/Activiti：提交缺陷修复和功能改进代码（已合并） react-dnd/react-dnd：添加新的场景使用示例（未被接受，已关闭） mitre/HTTP-Proxy-Servlet：缺陷修复（已合并） hawtio/hawtio-oauth：缺陷修复（已合并） … 项目经验 在部门内引入并推广Maven项目构建、CI/CD持续集成、Git源码管理、统一登录（SSO）、代码分支管理、Wiki文档管理、代码质量控制、缺陷管理等开发机制和流程，并独立搭建相关环境，进而提升部门产品的开发、测试、发布效率 将部门内的运维工具、产品演示服务、产品演示数据库等全部容器化部署和管理，从而降低运维难度和工作量 尝试部署高可用的Kubernetes集群，并在其上搭建DevOps和日志分析平台，但由于机房环境和主机设备不稳定等因素影响而始终未能如愿 编写Ansible Playbook脚本为客户搭建具备3个Master节点的高可用Kubernetes集群环境，并在其上部署和运行部门的产品，实现运维产品服务的高可用 负责分析并查找产品性能低下、高内存占用、数据库连接池耗尽等问题，通过JVM内存分析、接口调用监控等方式最终定位根源并有针对性地提出改进和规避方案 负责维护和开发部门的运维产品，设计并实现多个核心组件和功能模块，如，CI关系视图、数据归档、数据访问权限控制、Hibernate热加载/热更新BO Class等 自行设计并实现类似Jenkins Pipeline的任务调度和编排机制，支持任务调度、解析和执行Pipeline脚本（Groovy）、本地或远端执行Bash脚本、文件传输、运行Ansible Playbook等功能 基于mxGraph JS图形库设计并开发CMDB资产生命周期（入库、出库、维护等）设计器 基于Activiti 5流程引擎做业务层封装，支持在不修改源码的基础上做业务功能扩展和增强：外部人员组织机构适配；流程跳转、委办、退回、会签等 基于Apache Camel实现多类型接收端点的消息发送框架 基于Vue.js设计并开发UI设计器，但由于设计的复杂度、个人整体把控能力不足等问题而最终被搁置 基于YAVI Java API开发VMware vCenter集群管理的组件库，支持对虚拟主机、网络等资源的管理 基于fabric8io/kubernetes-client设计并开发多租户平台，实现将部门的运维产品按租户部署至Kubernetes集群并独立运行和访问 基于Electron为客户开发自助服务终端App，支持身份证读取和二维码扫描功能"},{"title":"Categories","permalink":"https://flytreeleft.github.io/categories/index.html","text":""},{"title":"Simple words for me and you","permalink":"https://flytreeleft.github.io/quotes/index.html","text":"Time is your best precious treasure, please use it as better as you can.时间是你拥有的最大财富，请好好利用它！ There is no retribution only cause and result.这世间没有「报应」，只有「因果」。 The other’s success isn’t yours, but the failure will be.成功者的成功不会是你的成功，失败者的失败必然是你的失败。 Thousands of little steps make the great miles away, thousands of little rivers make the great ocean.不积跬步，无以至千里；不积小流，无以成江海。 If no actions, your dream will still be a dream forever.如果不付诸行动，你的梦想将永远只是梦想。 Human beings are not afraid of the death, but they are just obsessed with something.人类害怕的并不是死亡本身，只是对某些东西会念念不忘而以。"},{"title":"Tags","permalink":"https://flytreeleft.github.io/tags/index.html","text":""}],"posts":[{"title":"内存都去哪儿了","permalink":"https://flytreeleft.github.io/the-jvm-dump-analyse-for-where-is-the-memory/","text":"提要在开始分析之前先了解一下下面几个相关术语： Shallow Heap：对象自身占用的内存大小（包含基本数据类型），不包括它引用对象的大小； Retained Heap：Shallow Heap + 所有直接或者间接引用对象占用的内存（即该对象被GC回收后，可以被回收的内存）； GC Root：被堆外对象引用的对象； Dominator Tree：以支配树方式描述的对象引用关系； 有关JVM内存转储方式的说明见JVM内存分析：Tomcat内存泄漏。 案例分析最近服务器的内存又在狂飙了，网关响应缓慢，Jenkins完成构建需要长达2个多小时。到底疯狂到什么程度呢？用htop命令看看： 不仅64G内存几乎耗尽，还占用了大量的交换分区空间（也就是虚拟内存），实在异常恐怖！ 再查看哪些进程耗用内存较多，结果发现都是Docker容器内的应用进程消耗最多。那使用命令docker stats --format &quot;table {{.Name}}\\t{{.Container}}\\t{{.CPUPerc}}\\t{{.MemUsage}}\\t{{.NetIO}}\\t{{.BlockIO}}&quot;看看各个容器的内存使用情况： 从使用情况来看，有多个应用容器的内存使用量在5GB以上，而且部分应用实际上并没有什么耗内存的地方，却也占用了5GB，实在是不可理喻。 没有办法了，只能dump出应用的堆内存，再详细分析内存都消耗在哪些对象上了。 在容器内运行命令sudo -u tomcat jmap -dump:format=b,file=heap-dump.bin &lt;java_pid&gt;将Tomcat进程的堆内存转储至heap-dump.bin中。 转储完成后，通过Eclipse Memory Analyzer - MAT自带的工具ParseHeapDump.sh分析堆内存（也同时分析其中的unreachable对象以得到对象内部数据）：ParseHeapDump.sh -keep_unreachable_objects heap-dump.bin。 最后，启动MAT并点击菜单File -&gt; Open Heap Dump选择文件heap-dump.bin，得到如下结果： 结果很出乎意料：int[]数组居然占用了数十兆内存，总计占了1/4！ 接着看看直方图（Histogram），注意需将结果按Shallow Heap降序排序： 这更是惊人：int[]数据总共为505,211,152字节，也就是481MB！ 惊讶继续！ 右键点击int[]并选择List objects -&gt; with incoming references（PS：同样按Shallow Heap降序排序）： 从incoming references中可以发现以下问题： 几乎所有的int[]都是unreachable的； 靠前的int[]长度都达到数十万，甚至百万、千万； 那么，问题来了： 谁创建了这么多且这么大的数组，又为何创建？ 数组里存的是什么数据，干什么用的？ 第一个问题没有可解答的线索，因为查不到引用这些数组的对象。不过从第二个问题中应该能找寻到一些蛛丝马迹。 在incoming references中右键点击第一条并选择Copy -&gt; Save Value To File，将数组内的数据保存到文件int-bytes.bin中。 因为得到的文件为二进制的，故需使用工具hexedit查看其内容（PS：也可用其他二进制查看工具）。 打开文件后向下翻页直至右侧出现有大量连续可识别的字符为止： 截取其中的一段内容： 12345678002CEEA8 00 00 00 00 00 00 00 00 00 00 00 01 00 00 00 00 F8 00 00 ED 00 00 00 3A 41 54 45 4D 46 4E 49 2D 72 65 73 2F 65 63 69 76 .......................:ATEMFNI-res/eciv002CEED0 61 6A 2F 73 2E 78 61 76 2E 6C 6D 78 73 72 61 70 2E 73 72 65 75 63 6F 44 74 6E 65 6D 6C 69 75 42 46 72 65 64 6F 74 63 61 aj/s.xav.lmxsrap.sreucoDtnemliuBFredotca002CEEF8 00 00 79 72 00 00 00 00 00 00 00 01 00 00 00 00 F8 00 00 3F 00 00 00 3A 00 45 00 4D 00 41 00 54 00 49 00 2D 00 46 00 4E ..yr...............?...:.E.M.A.T.I.-.F.N002CEF20 00 73 00 2F 00 72 00 65 00 69 00 76 00 65 00 63 00 2F 00 73 00 61 00 6A 00 61 00 76 00 2E 00 78 00 6D 00 78 00 2E 00 6C .s./.r.e.i.v.e.c./.s.a.j.a.v...x.m.x...l002CEF48 00 61 00 70 00 73 00 72 00 72 00 65 00 2E 00 73 00 6F 00 44 00 75 00 63 00 65 00 6D 00 74 00 6E 00 75 00 42 00 6C 00 69 .a.p.s.r.r.e...s.o.D.u.c.e.m.t.n.u.B.l.i002CEF70 00 65 00 64 00 46 00 72 00 63 00 61 00 6F 00 74 00 79 00 72 00 00 00 00 00 00 00 01 00 00 00 00 F8 00 00 ED 00 00 00 AE .e.d.F.r.c.a.o.t.y.r....................002CEF98 41 54 45 4D 46 4E 49 2D 72 65 73 2F 65 63 69 76 61 6A 2F 73 2E 78 61 76 2E 6C 6D 78 73 72 61 70 2E 73 72 65 75 63 6F 44 ATEMFNI-res/ecivaj/s.xav.lmxsrap.sreucoD002CEFC0 74 6E 65 6D 6C 69 75 42 46 72 65 64 6F 74 63 61 00 00 79 72 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 tnemliuBFredotca..yr.................... 这里会发现一个问题：这些字符看起来很有规律，感觉很熟悉但却又很陌生。 不过仔细辨别还是可以发现：每四个相邻字符反序再组合也就能够还原出正确的字符串。比如，截图中便可识别出一串字符：META-INF/services/javax.xml.parsers.DocumentBuilderFactory。 为什么转存的二进制文件会出现字符串反序呢？其实，这便是著名的大小端字节序。而该文件正好为小端字节序（低位字节在前，高位字节在后），和人类的读写顺序（大端字节序）正好相反。 有点「反人类」了。 为了确保能正常识别int[]中存储的内容，我们需要将小端字节序转换为大端字节序。 不幸的是，没能找到直接可用的大小端转换工具，于是拿起遗忘已久的C语言编写以下一段代码来进行转换： 123456789101112131415161718192021222324252627282930313233343536#include &lt;stdint.h&gt;#include &lt;stdio.h&gt;// https://stackoverflow.com/questions/2182002/convert-big-endian-to-little-endian-in-c-without-using-provided-func#answer-2637138uint32_t swap_uint32( uint32_t val ) &#123; val = ((val &lt;&lt; 8) &amp; 0xFF00FF00 ) | ((val &gt;&gt; 8) &amp; 0xFF00FF ); return (val &lt;&lt; 16) | (val &gt;&gt; 16);&#125;int main (int argc, char *argv[]) &#123; char *in = argv[1]; char *out = argv[2]; FILE *file_in = fopen(in, \"r\"); FILE *file_out = fopen(out, \"w\"); if (file_in == NULL) &#123; fprintf(stderr, \"File '%s' not found!\\n\", in); return -1; &#125; fprintf(stdout, \"Reading from '%s'\\n\", in); uint32_t value; while (fread(&amp;value, sizeof(value), 1, file_in) == 1) &#123; uint32_t new_value = swap_uint32(value); if (fwrite(&amp;new_value, sizeof(new_value), 1, file_out) != 1) &#123; fprintf(stderr, \"Failed to write to file '%s'!\\n\", out); break; &#125; &#125; fprintf(stdout, \"[DONE] Write to '%s'\\n\", out); fclose(file_out); fclose(file_in); return 0;&#125; 使用GCC编译（gcc -o swap-endian main.c）并运行swap-endian以转换大小端：./swap-endian ./int-bytes.bin ./int-bytes.bin.swap。 然后，再用hexedit打开int-bytes.bin.swap并按组合键Ctrl+G跳转到刚才查看的位置。这下字符顺序终于正常了： 反序问题解决了，接下来就来擦亮眼睛去发现int[]中都有些什么吧。 最后从该数组中发现其包含了以下一些字符串： jar:file:/xxx/xxx/xxx.jar META-INF/services/xxx.xxx.XxxXX /usr/lib/jvm/java-8-openjdk-amd64/jre/lib/xerces.properties com/sun/org/apache/xpath/internal/jaxp/XPathFactoryImpl.class org/activiti/db/mapping/entity/Task.xml（及其内容）、org.activiti.engine.impl.TablePageMap.class jar:file:/xxx/xxx/WEB-INF/lib/xercesImpl-2.6.2.jar!/META-INF/services/javax.xml.parsers.DocumentBuilderFactory 有什么发现没？反正我是感觉这可能是ClassLoader的内容或者与此相关的某些东西。而且这些也不是业务对象数据，基本都是*.class、*.java以及jar中的资源文件的名称和内容，那这就和应用本身没啥关系了，问题出在JVM层面的可能性更大。 如果是这样，那为何会出现这样的问题呢？ 我也是茫然无知，多番假设和验证后也没有结果，最后，只得Google了一下关键字java big int array unreachable，并从Java String objects not getting garbage collected on time中找到了些线索： This means the VM will eat memory until it hits the maximum and then, it will do one huge GC run：即，Java GC的开销很大（evil），因此其会尽可能多地使用内存直到超过最大限定值，非万不得已不会主动GC Unless you see OutOfMemoryException, you don&#39;t have a leak：即，如果没有抛出OutOfMemoryException异常，那么就不会是内存泄漏，那怕是内存被全部耗尽 However when we inspect these char[], Strings we find that they do not have GC roots which means that they shouldn&#39;t be the cause of leak. Since they are a part of heap, it means they are waiting to get garbage collected：即，Unreachable对象不会引发内存泄漏，其属于堆内数据，正等待被垃圾回收 联系实际情况：在Docker镜像构建配置中，Tomcat的启动脚本并未设置JVM的堆大小，而且从长时间的观察来看，容器的内存消耗会随时间逐步增长，并且在多次数据查询后内存使用也是会直线增长。再结合以上线索，便可初步确定这是JVM没有GC造成的。 按照以上思路，为Tomcat启动脚本设置JVM堆内存的最大值和初始值，再重启并运行一段时候后发现容器的内存使用情况趋于正常，静默下的内存消耗降至百兆，有数据查询时内存使用会上升到1GB左右，并在没有数据查询时出现回落： 内存使用也回归正常： 看来问题还真就是出在JVM的GC机制上，悬了长久的问题终于得到解决。 这里不禁要感叹： 原来你是这样的Java！！ 解决方案对症下药，调整Docker镜像的entrypoint脚本为如下内容（PS：非全部内容，需根据实际情况调整）： 12345678910111213141516# 在JDK8以前的版本中需将“-XX:MetaspaceSize=512m -XX:MaxMetaspaceSize=512m”改为“-XX:PermSize=512m -XX:MaxPermSize=512m”java -Dcatalina.base=$&#123;TOMCAT_BASE&#125; \\ -Dcatalina.home=$&#123;TOMCAT_HOME&#125; \\ -Dwtp.deploy=$&#123;TOMCAT_BASE&#125; \\ -Djava.util.prefs.userRoot=$&#123;JAVA_USER_PREFS&#125; \\ -Djava.endorsed.dirs=$&#123;TOMCAT_HOME&#125;/endorsed \\ -Djava.util.logging.config.file=$&#123;TOMCAT_BASE&#125;/conf/logging.properties \\ -Dfile.encoding=UTF-8 \\ -server \\ -Xms1G -Xmx1G \\ -XX:MetaspaceSize=512m -XX:MaxMetaspaceSize=512m \\ -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=$&#123;TOMCAT_HOME&#125;/memdump.hprof \\ -XX:+PrintGCDetails -XX:+PrintGCCause -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps \\ -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=5 -XX:GCLogFileSize=10M -Xloggc:$&#123;TOMCAT_HOME&#125;/gc.log \\ -classpath $&#123;TOMCAT_HOME&#125;/bin/bootstrap.jar:$&#123;TOMCAT_HOME&#125;/bin/tomcat-juli.jar:$&#123;JAVA_HOME&#125;/lib/tools.jar \\ org.apache.catalina.startup.Bootstrap start 对Tomcat调整Java参数，需新增或编辑文件${TOMCAT_HOME}/bin/setenv.sh，并按这里的内容调整环境变量JAVA_OPTS的值。 在以上脚本中还指定了出现OOM时的堆转储文件以及GC日志的存储位置。 获取到GC日志后可以通过在线工具GCeasy分析JVM的GC情况。注意：在生产环境中也应该设置OOM时的堆转储文件以便于分析内存溢出问题。 注意，以上内容并不一定是最佳设置，需根据实际情况进行调整，如果存在以下情况，可尝试适当增加-Xms（初始堆内存）和-Xmx（最大堆内存）的值： 应用需要加载大量的Class； 应用运行期间需要创建大量对象或在数组中存放大量数据； 从GC日志中发现进行GC的频率较高、间隔较短； 通过GCeasy也可以得到很好的改进建议；堆内存分配过大会导致一次GC的耗时增加，而GC操作会挂起应用，因此，不可盲目设置过大值； GC日志行的格式说明如下（Understanding Garbage Collection Logs）： 参考 Eclipse Memory Analyzer - MAT Java String objects not getting garbage collected on time What are the Xms and Xmx parameters when starting JVMs? 排查Java的内存问题 Java中堆内存和栈内存详解 How to Enable Garbage Collection (GC) Logging Understanding Garbage Collection Logs：解释GC (Allocation Failure)行的格式 JVM调优经验 JVM参数优化（基础篇） 附录${TOMCAT_HOME}/bin/setenv.sh12345678910111213141516171819202122#!/bin/shJAVA_OPTS=\"$JAVA_OPTS -Dfile.encoding=UTF-8\"# Prevent to occur the error 'java.lang.NoClassDefFoundError: Could not initialize class javax.imageio.ImageIO'JAVA_OPTS=\"$JAVA_OPTS -Djava.awt.headless=true -Dawt.toolkit=sun.awt.HToolkit\"JAVA_OPTS=\"$JAVA_OPTS -server\"JAVA_OPTS=\"$JAVA_OPTS -Xms1G -Xmx1G\"# PermGen for JDK7, JDK6JAVA_OPTS=\"$JAVA_OPTS -XX:PermSize=512m -XX:MaxPermSize=512m\"# PermGen for JDK8+#JAVA_OPTS=\"$JAVA_OPTS -XX:MetaspaceSize=512m -XX:MaxMetaspaceSize=512m\"# Print heap dump logJAVA_OPTS=\"$JAVA_OPTS -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=$&#123;CATALINA_HOME&#125;/memdump.hprof\"# Print GC logJAVA_OPTS=\"$JAVA_OPTS -XX:+PrintGCDetails -XX:+PrintGCCause -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps\"JAVA_OPTS=\"$JAVA_OPTS -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=5 -XX:GCLogFileSize=10M\"JAVA_OPTS=\"$JAVA_OPTS -Xloggc:$&#123;CATALINA_HOME&#125;/gc.log\""},{"title":"数据库连接池耗尽","permalink":"https://flytreeleft.github.io/the-jvm-dump-analyse-for-connection-pool-exhausted/","text":"提要由于数据库连接十分耗时，采取即需即连的方式会导致应用响应缓慢，因此，在Java应用中均采用数据库连接池统一维护一定数量的Connection对象，连接池中的Connection均保持与数据库的长连接，这样，该连接将随时可用，从而提高应用响应和处理速度。 但是，在普遍的使用不当的情形中，最多的问题便是没有及时释放连接，这里的释放是指将Connection对象归还连接池。若连接未被释放，则连接池将被很快耗尽（Exhausted），从而无法提供新的连接，最终导致应用不能进行数据库操作，并在尝试获取新的连接时出现以下异常：123456789101112131415161718192021...Caused by: org.hibernate.exception.GenericJDBCException: Could not open connection at org.hibernate.exception.internal.StandardSQLExceptionConverter.convert(StandardSQLExceptionConverter.java:54) at org.hibernate.engine.jdbc.spi.SqlExceptionHelper.convert(SqlExceptionHelper.java:125) at org.hibernate.engine.jdbc.spi.SqlExceptionHelper.convert(SqlExceptionHelper.java:110) at org.hibernate.engine.jdbc.internal.LogicalConnectionImpl.obtainConnection(LogicalConnectionImpl.java:221) at org.hibernate.engine.jdbc.internal.LogicalConnectionImpl.getConnection(LogicalConnectionImpl.java:157) at org.hibernate.internal.SessionImpl.connection(SessionImpl.java:550) at org.springframework.orm.hibernate4.HibernateTransactionManager.doBegin(HibernateTransactionManager.java:426) ... 9 moreCaused by: org.apache.commons.dbcp.SQLNestedException: Cannot get a connection, pool error Timeout waiting for idle object at org.apache.commons.dbcp.PoolingDataSource.getConnection(PoolingDataSource.java:114) at org.apache.commons.dbcp.BasicDataSource.getConnection(BasicDataSource.java:1044) at org.hibernate.service.jdbc.connections.internal.DatasourceConnectionProviderImpl.getConnection(DatasourceConnectionProviderImpl.java:141) at org.hibernate.internal.AbstractSessionImpl$NonContextualJdbcConnectionAccess.obtainConnection(AbstractSessionImpl.java:292) at org.hibernate.engine.jdbc.internal.LogicalConnectionImpl.obtainConnection(LogicalConnectionImpl.java:214) ... 12 moreCaused by: java.util.NoSuchElementException: Timeout waiting for idle object at org.apache.commons.pool.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:1174) at org.apache.commons.dbcp.PoolingDataSource.getConnection(PoolingDataSource.java:106) ... 16 more 案例分析 有关JVM内存转储方式的说明见JVM内存分析：Tomcat内存泄漏。 在本案例应用（约定称为「应用A」）的使用过程中偶尔会在前端弹出Timeout waiting for idle object的异常提示框。经过查看完整的异常堆栈（看上面）可发现，异常发生在从连接池获取Connection时，在对GenericObjectPool源码分析后可初步确定是因为连接池已满而无法分配新的Connection造成的。 为进一步确认该问题，将应用A的内存转储（sudo -u tomcat jmap -dump:format=b,file=heap-dump.bin &lt;java_pid&gt;）并通过Eclipse Memory Analyzer - MAT对其内存进行分析。 点击工具栏中的OQL图标，这里需要通过OQL进行一些复杂的过滤查询（OQL：SELECT OBJECTS ds FROM org.apache.commons.dbcp.BasicDataSource ds）： OQL的语法可从MAT的Help -&gt; Help Contents菜单中进入帮助手册查询到； org.apache.commons.dbcp.BasicDataSource为应用中使用的DataSource的实现类，其内部引用org.apache.commons.dbcp.PoolingDataSource，并在PoolingDataSource中负责从连接池申请新的连接； 从图中可以看到，连接池org.apache.commons.pool.impl.GenericObjectPool的_numActive为749，而在应用中为其分配的最大活跃连接数（maxActive）为750。因此，可以进一步确定连接池的确已达到分配上限，在并发情况下将不会再分配更多连接，从而导致等待超时并抛出异常。 再看看内存中是否存在未被释放的MySQL连接。 由于MAT默认不分析unreachable对象，所以，在开始前需通过其自带的工具ParseHeapDump.sh（或ParseHeapDump.bat）分析不可达对象： 12# 运行该命令前需删除dump文件所在目录中由MAT生成的分析文件$ ParseHeapDump.sh -keep_unreachable_objects heap-dump.bin 点击MAT的菜单File -&gt; Open Heap Dump选择文件heap-dump.bin载入转储分析文件，然后，通过OQL（SELECT cn, cn.isClosed, cn.io.mysqlConnection, cn.io.mysqlConnection.closed FROM INSTANCEOF com.mysql.jdbc.JDBC4Connection cn）得到MySQL Connection对象如下： 点击工具栏中的分组图标可按照Class Loader对结果进行分组；在MySQL驱动中的Connection所引用的相关对象为： com.mysql.jdbc.JDBC4Connection#io:com.mysql.jdbc.MysqlIO com.mysql.jdbc.MysqlIO#mysqlConnection:java.net.Socket java.net.Socket#closed:boolean 可以发现，在36个连接中仅有2个是正常关闭的，其余的Connection未被关闭，但对应的Socket连接却处于关闭状态。这里可以假设出以下两种可能的情形： Connection在使用时出现网络中断，导致Socket非正常关闭； Connection在使用后未被正常关闭，并且在某个时刻发生了Socket连接中断； 对于第一种情形，Socket的异常关闭势必会抛出异常，并最终在使用方拦截到该异常并关闭Connection，而这里的Connection为非关闭状态，说明使用方并未准确做资源的释放处理。第二种情形，自然也是因为资源未被及时释放了。 因此，Connection没有被及时、准确地释放是相当肯定的事情了。 但这里依然有个疑问，为啥连接池里记录分配的连接为749，而实际查到的Connection对象只有30多个，其余的哪儿去了？ 针对上述问题，限于基本功的问题，目前还没有确切的定论，但大致可推断是MySQL驱动中的com.mysql.jdbc.AbandonedConnectionCleanupThread对弱引用的com.mysql.jdbc.JDBC4Connection对象做了资源主动回收处理： com.mysql.jdbc.NonRegisteringDriver.ConnectionPhantomReference为虚引用类java.lang.ref.PhantomReference的扩展类，其将在java.lang.ref.Reference.ReferenceHandler#run中等待JVM启动GC时进行清理活动。 Java引用相关的知识可阅读详解java.lang.ref包中的4种引用。 既然得到了看似很有道理的分析结论，那就应该有方法复现当前的问题。 首先，通过IDE工具查找应用中主动获取Connection对象而未释放的代码位置，最终找出以下几处： xx/xx/xx/XxQueryImpl.java @r74605: L357, L1607 … 经过调用分析后，可找到以下几个相关的Web API以用于复现验证： /a/xx/queryXx.mvc /a/xx/countXx.mvc … 需要注意的是，一般MySQL服务端会限定并发连接数，为了快速复现当前问题，可通过以下语句调整MySQL的默认最大连接数（重启后将失效）： 12-- 查看默认配置： show variables like '%connect%';SET GLOBAL max_connections = 850; 在登录应用A后，在浏览器控制台中执行以下代码便可复现最开始提到的异常问题： 1234567891011121314151617181920212223242526var ctx = '/a';var urls = [ ctx + '/xx/queryXx.mvc', ctx + '/xx/countXx.mvc'];var waitTime = 0.1 * 1000;function doRequest(urls, index) &#123; if (!urls || urls.length === 0) return; var i = index || 0; var url = urls[0]; $.ajax(&#123;url: url, success: function () &#123; console.log(i, url, arguments); setTimeout(function() &#123; doRequest(urls.slice(1), i + 1); &#125;, waitTime); &#125;&#125;);&#125;var requestCount = 800;var requestURLs = [];for (var i = 0; i &lt; requestCount / urls.length; i++) &#123; requestURLs = requestURLs.concat(urls);&#125;doRequest(requestURLs); 解决方案找到了根本原因，解决方案就很简单了： 在try {...} finally {...}语句的finally块中关闭主动获取的Connection对象。 而本案例中的业务需求似乎比较特殊，具体方案需根据实际业务需求确定，但必须坚持以下原则： 在finally块中释放主动获取的Connection对象； 数据库类型无关：尽可能避免在代码中根据数据库类型做条件判断，首选HQL所支持的数据库无关的查询语句和表达式 参考 Eclipse Memory Analyzer - MAT Querying Java heap with OQL OQL"},{"title":"JVM内存分析：Tomcat内存泄漏","permalink":"https://flytreeleft.github.io/the-jvm-dump-analyse-for-tomcat-memory-leak/","text":"提要通过内存转储可对Java应用内各对象的内存使用情况进行分析，从而找出过度消耗内存或无法及时释放的对象，进而为异常修复以及提升应用加载速度和运行性能提供帮助。 内存转储使用JDK自带的工具jmap（sudo -u tomcat jmap -dump:format=b,file=heap-dump.bin &lt;java_pid&gt;）将应用内存以二进制格式转储到heap-dump.bin中。 需确保转储用户与线程用户相同，否则会出现Unable to open socket file: target process not responding or HotSpot VM not loaded的问题； 转储文件可能会被放到临时目录中，该目录会在Tomcat重启时被删除，所以，一定要在重启前将转储文件转移到安全位置； 转储的文件一般为GB级，可通过命令xz -k heap-dump.bin进行高强度压缩，得到压缩文件heap-dump.bin.xz。解压使用命令unxz -k heap-dump.bin.xz，其中，-k选项均表示保留原文件，否则原文件将会被删除； 得到内存转储文件后，可通过Eclipse Memory Analyzer - MAT对其进行分析。由于转储文件较大，所以，分析工具也需要分配较大内存方可正常运行，需编辑文件MemoryAnalyzer.ini，修改或添加-Xmx4g以增加MAT的堆内存。 在开始分析之前先了解一下下面几个相关术语： Shallow Heap：对象自身占用的内存大小（包含基本数据类型），不包括它引用对象的大小； Retained Heap：Shallow Heap + 所有直接或者间接引用对象占用的内存（即该对象被GC回收后，可以被回收的内存）； GC Root：被堆外对象引用的对象； Dominator Tree：以支配树方式描述的对象引用关系； 案例分析应用运行环境： 独立的Docker容器 JDK8 + Tomcat8 Tomcat内运行有A和B两个业务应用，其他为Tomcat自带的docs、manager、examples、host-manager、ROOT（五个）应用 在开发环境中，应用经常出现内存泄漏（OutOfMemoryError：Permgem space）。其每次重启并运行一段时间后，也会消耗掉大量内存： 内存泄露：指程序中动态分配内存给一些临时对象，但是对象不会被GC所回收，它始终占用内存。即被分配的对象可达但已无用。 内存溢出：指程序运行过程中无法申请到足够的内存而导致的一种错误。内存溢出通常发生于Old段或Perm段垃圾回收后，仍然无内存空间容纳新的Java对象的情况。 从图中可以看到，Tomcat进程占用了接近50%的内存（8G+），这对仅有少量访问的应用来说是很不正常的。 话不多说，直接使用jmap（sudo -u tomcat jmap -dump:format=b,file=heap-dump.bin &lt;java_pid&gt;）将Tomcat的内存转储并下载到本地。再通过MAT对其进行分析。 这里得到的分析结果如下： 然后，打开Dominator Tree以检查当前占用内存最高的有哪些对象： 从中可发现SessionFactoryImpl和ParallelWebappClassLoader的内存占用比例最高，并且，在对结果进行正则过滤后可以发现： 这两个Class存在多个实例，其中，SessionFactoryImpl有10个实例，而ParallelWebappClassLoader有15个实例； 各个SessionFactoryImpl实例的Class以及Class Loader的地址均不相同； 而所有ParallelWebappClassLoader的Class和Class Loader的地址却是相同的； 另外，可以看到SessionFactoryImpl的Class Loader均为ParallelWebappClassLoader； 在Tomcat7和Tomcat8中默认的Class Loader为ParallerWebappClassLoader以支持Class并行加载，提高加载效率（并行加载机制需JDK7+环境）。 根据Java Class的加载原理可知，每个Class均对应一个唯一的Class Loader，不同的Class Loader所加载的Class是不同的，即使是Class名称（含包名）完全一致，也是互不相等的。也就是说，在当前的Tomcat内不仅存在多个SessionFactoryImpl实例，还同时存在多个SessionFactoryImpl的Class。 打开Histogram看看在Tomcat中存在多少个Class，而每个Class又产生了多少实例： 对上述两个目标过滤后可以发现，在Tomcat中确实存在10个同名的SessionFactoryImpl类，每个类均产生了一个实例，而ParallelWebappClassLoader虽然只有一个类，但却创建了15个实例。这和我们所预期的共识产生了明显冲突： Tomcat应该为每个应用创建且仅创建一个Class Loader以隔离不同的应用，加上Tomcat自带的应用，总共应该只有7个Class Loader才对； Hibernate SessionFactory在单个应用内应该是单例的，而在本案例中只有A和B两个应用才会创建SessionFactory实例，其实例数最多只能有两个； 于是抛出以下问题： Tomcat因为什么原因创建了额外的8个Class Loader？ 额外的8个Hibernate SessionFactory实例又是为何创建的？ Tomcat高内存占用是因为Class被重复加载以及存在相同的活跃对象所造成的？ 先来看看Class Loader的GC Root引用情况（在Histogram内选中目标，再右键选择Merge Shortest Paths to GC Roots）： 从结果中可以看到，Class Loader实际被11条线程所引用，通过名称可以判断有5条是应用所创建的Deamon线程，以及一条Hibernate Search线程和一条Tomcat的线程。 如此看来，Class Loader是被不同的线程所引用的，那很有可能是因为这些线程遇到死锁或长时间的阻塞而造成了其无法被及时回收，从而导致PermGen（永生代，负责存放Class、静态变量、常量等）内存被耗尽。 还可以怀疑ASM的动态特性是否会创建新的Class Loader实例。可能性是有的，但仔细分析也可以发现，若其自行实例化加载器，即使不考虑性能问题，其又如何确定从何处加载所需的Class？很明显，利用当前的Class Loader才是明智的选择。看看Tomcat源码WebappLoader.java的第394行就知道自己去实例化Class Loader是多么不可靠： 既然提到了Tomcat的源码，那就干脆把代码check下来研究一下（https://github.com/apache/tomcat/ ，本例使用分支tag/8.5.6）。 先看看ParallelWebappClassLoader是怎么回事。 该类本身逻辑很少，但其继承的父类WebappClassLoaderBase却责任重大，需要做Class的加载和查询工作。该父类包含众多属性，而其中值得关注的是类型为LifecycleState的state属性，显然，这说明这个Class Loader是具有生命周期的，并且，很明显只能由Tomcat来控制其生命周期，因为其他Class无法知道其存在。 既然，ParallelWebappClassLoader包含这么多属性，那看看在前面发现的那些实例的state属性有何不同。 依然在Histogram中选中目标，在右键菜单中选择List objects -&gt; with outgoing references，跳转到： 展开每个实例，检查各实例的state情况： 检查后发现，有8个实例的state为DESTROYED，7个为STARTED。这说明，有8个Class Loader实际已经被销毁，只有7个是活跃的。再对前面的GC Root列表里的线程所引用的Class Loader进行比对，可以发现有8条线程正好引用的是这8个被销毁的Class Loader，也就是说： Tomcat在销毁Class Loader后，因线程无法被终止而使得该线程所引用的Class Loader无法被回收，进而导致该Class Loader所加载的Class也不会被回收，而线程所引用的实例对象也就同样无法被回收，其中，就包含SessionFactoryImpl； 这里的几个数字也很值得关注：8，7，5。正常情况下，Tomcat应该创建5+2（5个Tomcat自带应用，2个业务应用）个Class Loader，这正好是7个活跃态的Class Loader。那么，现在的这15个Class Loader都对应了哪些应用呢？ 有过以编码方式内嵌Jetty等Servlet容器开发经验或者阅读过Tomcat源码的开发者应该知道，Servlet容器一般会有一个Context对象用以记录加载的webapp的名字、目录等信息，而Tomcat的该类的实现为org.apache.catalina.core.StandardContext。所以，找到ParallelWebappClassLoader关联的Context，就可以知道其负责加载的是哪个应用了。 在前面打开的outgoing references列表中查找Tomcat内的对象，最终发现ParallelWebappClassLoader的resources#context正是我们要找的： 挨个检查后发现，7个活跃的Class Loader分别对应着Tomcat所加载的7个应用，但剩下的8个却没有resources属性。属性不存在，说明其应该是被置为了null，这也进一步验证Class Loader的确是被销毁了，且只能是被Tomcat销毁的。 到这里，事情还没有结束，因为还不知道其他8个Class Loader是哪个（或哪些）应用产生的呢！ 试试从加载的jar等资源的路径来判断加载的是哪个应用？ 在查遍可能的属性后，最终发现，在ParallelWebappClassLoader#localRepositories中便记录了所有加载的jar的URL地址： 这下才算是圆满了，被销毁的8个Class Loader均对应到应用A的部署位置，也就是说，Tomcat对应用A进行过至少8次销毁处理。 被销毁8次？！这两者为何如此「苦大仇深」呢？ 前面已经讨论过，销毁必然只能由Tomcat来做，应用内部不应该也没法主动进行销毁，除非有针对性的代码，但应用A中并没有提供这样的机制。 那继续分析Tomcat的源码。 在前面有提到ParallelWebappClassLoader#state的值会发生变化，那就找找代码里在哪些地方修改了该状态： 跟踪接口调用情况，可以发现在WebappLoader中实施了销毁动作： 最后的最后，发现Tomcat会在Class Loader中检查classpath中已加载的资源的变更情况，若发生变化，则将直接reload当前应用： 已加载指通过ClassLoader#getResourceAsStream或ClassLoader#findResource查找过的资源，在Tomcat中只有通过这两个接口查找到的资源才会被放到org.apache.catalina.loader.WebappClassLoaderBase#resourceEntries列表中。 这里记录下接口调用的跟踪路径： 查找引用：org.apache.catalina.loader.WebappClassLoaderBase#destroy 定位到：org.apache.catalina.loader.WebappLoader#stopInternal查找引用：org.apache.catalina.loader.WebappLoader（注：查找stopInternal的引用无法确定其真实调用位置） 定位到：org.apache.catalina.core.StandardContext#startInternal转到：org/apache/catalina/core/StandardContext.java:4977 查找引用：org.apache.catalina.core.StandardContext#getLoader 定位到：org.apache.catalina.core.ContainerBase.ContainerBackgroundProcessor#processChildren转到：org/apache/catalina/core/ContainerBase.java:1372 查找实现：org.apache.catalina.core.StandardContext#backgroundProcess 转到：org/apache/catalina/core/StandardContext.java:5545 查找实现：org.apache.catalina.loader.WebappLoader#backgroundProcess 转到：org/apache/catalina/loader/WebappLoader.java:292 查找实现：org.apache.catalina.core.StandardContext#reload直接定位到：org.apache.catalina.core.StandardContext#stopInternal转到：org/apache/catalina/core/StandardContext.java:5447 返回到：org.apache.catalina.loader.WebappLoader#stopInternal 分析org.apache.catalina.loader.WebappLoader#backgroundProcess的逻辑可以确定webapp重载的两个条件： 应用启用了reloadable； WEB-INF/classes或WEB-INF/lib内的资源发生了变化； 经过前面的全面分析，现在终于可以还原真相了： 应用A在部署时，启用了热加载机制（真实情况也的确如此）： 在CI构建中为了控制应用A和应用B的加载顺序，采用了定义&lt;Context/&gt;的方式按顺序加载两个应用； 不幸的是，从网上拷贝了别人的配置，因而保留了reloadable=&quot;true&quot;的设定：&lt;Context path=&quot;/app_a&quot; reloadable=&quot;true&quot; docBase=&quot;app_a.war&quot; /&gt;； 应用A在首次启动时会修改WEB-INF/classes/config.properties，而该文件会在org.springframework.beans.factory.config.PropertyPlaceholderConfigurer中通过ClassLoader#getResourceAsStream读取，从而被放入Tomcat的资源变更观察列表中，成为Tomcat的已加载资源； 首次启动会使Tomcat触发至少两次重载，从Tomcat的输出日志中可寻找到重载痕迹； 在应用A运行后，通过其配置中心也会造成对WEB-INF/classes/config.properties的修改，进而导致该应用再次被重载； 最后，加上应用A中存在无法结束的线程，使得其引用的对象以及关联的Class Loader无法被回收，从而导致内存消耗随着应用重载次数的增加而不断增加； 解决方案对症下药，给出如下解决方案： 对应用A禁用热加载，因为： 应用自身加载就很缓慢，无法做到快速重载； 对配置的调整是确保应用重启后配置内容不丢失，而不是为了重新加载配置； 热加载机制应尽量少用，以避免内存泄漏，或其他无法预期的问题； 改进并完善线程逻辑，避免出现死锁，同时，确保应用在销毁前能够结束全部的线程； 为了避免因线程无法终止而造成内存泄漏，使用线程需注意以下事项： 非阻塞型异步任务线程，需确保整个逻辑执行过程中没有阻塞、竞争、死循环等阻碍线程结束的情况出现。除此之外，无须其他处理（#异步任务线程）； 非I/O阻塞型守护线程，可按如下过程实现或改进代码（#非I/O阻塞型守护线程）： 引入信号变量interrupted，并重写java.lang.Thread#interrupt()接口，在其中将信号量置为true； 在interrupt()内继续调用super.interrupt();以确保能够打破等待局面（BlockingQueue为空的等待，或者，sleep未超时的等待）； 循环条件改为!this.interrupted，并在循环内捕获java.lang.InterruptedException，以便在发生中断异常后break循环； 如果，在中断后仍需处理已有数据，则捕获异常后不break循环，而是在while条件中增加数据队列是否为空的判断（#非I/O阻塞型守护线程（数据清理）），当然，得确保生产者已不再工作； I/O阻塞型守护线程，同样需重写java.lang.Thread#interrupt()接口，并在其中关闭I/O连接，以迫使守护线程因java.io.IOException而结束等待，并最终终止循环（#I/O阻塞型守护线程）； 对于在Spring Bean中维护的线程，需实现org.springframework.beans.factory.InitializingBean和org.springframework.beans.factory.DisposableBean两个接口： 在InitializingBean#afterPropertiesSet中创建并启动线程； 在DisposableBean#destroy中结束线程以及其他清理工作； 非Sping应用可考虑通过Runtime.getRuntime().addShutdownHook()注册一个终止其他线程的线程。也可以在应用退出的位置（比如，main结束前，或者在javax.servlet.ServletContextListener#contextDestroyed里）自行终止所有线程； 结束线程仅可调用接口java.lang.Thread#interrupt()，而java.lang.Thread#stop()已被官方明确不建议使用，原因是，强行终止线程不能确保资源被有效释放，只能自行做释放工作，也就是前面针对阻塞线程提到的几种结束方式； 守护线程指一直循环运行的线程，一般内部含有while循环； java.util.concurrent.BlockingQueue#take()和java.lang.Thread#sleep(long)均会阻塞线程，并且只有在等待过程中才能被interrupt并抛出中断异常； 线程内部在接收到中断消息后，会重置线程状态，因此，Thread.currentThread().isInterrupted()仅在中断刚好发生在没有等待（等待刚好被打破或者还在数据处理过程中）的情况下才会返回true，而在发生了中断异常后则为false。所以，该接口十分不可靠，建议不要使用； 参考 Eclipse Memory Analyzer - MAT 停止Java线程，小心interrupt()方法 Java Multithreading Steeplechase: Stopping Threads MemoryLeakProtection Anatomy of a PermGen Memory Leak 附录异步任务线程12345678public class AsyncTaskThread extends Thread &#123; @Override public void run() &#123; // NOTE：内部逻辑不能存在死锁、死循环、阻塞等代码 doOnceTimeTask(); &#125;&#125; 非I/O阻塞型守护线程1234567891011121314151617181920212223242526272829303132public class BlockingDaemonThread extends Thread &#123; private volatile boolean interrupted = false; private BlockingQueue queue; @Override public void interrupt() &#123; // 标记线程已被中断 this.interrupted = true; // 继续由父类传递中断消息，以确保处于等待中的队列能够结束等待。 // 队列为空时将一直等待，从而阻塞线程，只能由父类打破该状态。 super.interrupt(); &#125; @Override public void run() &#123; // 重置状态，以便复用线程 this.interrupted = false; // 中断消息可能发生在队列刚好结束等待时，此时，线程无法捕获中断异常，因此，需通过信号量的状态判断是否终止循环。 // 这里不使用Thread.currentThread().isInterrupted()，因为，这里希望在需要时能够重启该中断线程。 while (!this.interrupted) &#123; try &#123; Object data = queue.take(); processData(data); &#125; catch (InterruptedException e) &#123; // 接收到中断消息，结束循环。 // NOTE：此时，线程的中断状态已被重置！！ break; &#125; &#125; &#125;&#125; 非I/O阻塞型守护线程（数据清理）123456789101112131415161718192021222324252627282930public class CleanBlockingDaemonThread extends Thread &#123; private volatile boolean interrupted; private BlockingQueue queue; @Override public void interrupt() &#123; // 标记线程已被中断 this.interrupted = true; // 继续由父类传递中断消息，以确保处于等待中的队列能够结束等待。 // 队列为空时将一直等待，从而阻塞线程，只能由父类打破该状态。 super.interrupt(); &#125; @Override public void run() &#123; // 重置状态 this.interrupted = false; // 在接收到中断后，一直处理，直到队列为空。 // 如果没有中断，那就只能等待新的数据到来，或者，收到父类的中断消息 while (!this.interrupted || !queue.isEmpty()) &#123; try &#123; Object data = queue.take(); processData(data); &#125; catch (InterruptedException e) &#123; // NOTE：此时，线程的中断状态已被重置！！ &#125; &#125; &#125;&#125; I/O阻塞型守护线程1234567891011121314151617181920212223242526272829public class IOBlockingDaemonThread extends Thread &#123; private volatile boolean interrupted; private volatile ServerSocket server; @Override public void interrupt() &#123; this.interrupted = true; this.server.close(); &#125; @Override public void run() &#123; this.interrupted = false; this.server = new ServerSocket(9680); // 由于该线程内没有能接收中断消息的对象，中断异常永远不会发生，只能通过IO关闭异常终止循环。 // 这里为了确保万无一失，依然使用了中断消息变量。 while (!this.interrupted) &#123; try &#123; Socket socket = server.accept(); processSocket(socket); &#125; catch (IOException e) &#123; // 终止循环，退出线程 // NOTE：这里的线程状态不会变化！！ break; &#125; &#125; &#125;&#125;"},{"title":"算法分析：求解最长公共子序列","permalink":"https://flytreeleft.github.io/algorithm-finding-the-longest-common-sequence/","text":"算法分析系列文章中的代码可被任何人无偿使用于任何场景且无需注明来源也不必在使用前征得本文作者同意。 算法分析系列文章旨在传播准确、完整、简洁、易懂、规范的代码实现，并传授基本的编程思想和良好的编码习惯与技巧。 若文章中的代码存在问题或逻辑错误，请通过邮件等形式（见文章结尾）告知于本文作者以便及时修正错误或改进代码。 算法系列文章不可避免地会参考和学习众多网友的成果，在行文风格、内容及求解思路上也会进行借鉴，如有侵权嫌疑，请联系本文作者。 PS：若为转载该文章，请务必注明来源，本站点欢迎大家转载。 问题描述如果序列 S_1 中的所有元素按照其在 S_1 中的出现顺序依次出现在另一个序列 S_2 中，则称 S_1 为 S_2 的子序列。 子序列不要求位置的连续性（即，元素相邻），只要相对顺序不变即可。 若给定一个序列集合（数量大于或等于2，但通常为两个序列），则这些序列所共同拥有的子序列，称为公共子序列。而在这些公共子序列中长度最长的子序列则称为该序列集合的最长公共子序列（Longest Common Sequence, LCS）。 本例所要求的便是求解任意两个序列的最长公共子序列（可能存在多个不同的序列），并打印其长度及其其中的任意一个序列。 例如，序列 \\{ B, D, C, A, B, A \\} 和 \\{ A, B, C, B, D, A, B \\} 的最长公共子序列为 \\{ B, C, B, A \\} 和 \\{ B, D, A, B \\} ，且其最长公共子序列的长度为4。 求解方案动态规划法首先，对最长公共子序列的求解过程做如下数学推导。 假设，存在序列集合 X_i=\\{ x_1, x_2, ..., x_i \\} 和 Y_j=\\{ y_1, y_2, ..., y_j \\} ，其最长公共子序列为 Z_k=\\{ z_1, z_2, ..., z_k \\} 。则存在以下情况： 若 x_i=y_j ，则有 z_k=x_i=y_j ，且 Z_{k-1}=\\{ z_1, z_2, ..., z_{k-1} \\} 是 X_{i-1}=\\{ x_1, x_2, ..., x_{i-1} \\} 与 Y_{j-1}=\\{ y_1, y_2, ..., y_{j-1} \\} 的一个最长公共子序列 若 x_i \\neq y_j ，则若 z_k \\neq x_i ，那么， Z_k 是 X_{i-1} 与 Y_j 的一个最长公共子序列。注：此时 z_k 不一定等于 y_j ，但该推论是包含等于或不等于的情况的 若 x_i \\neq y_j ，则若 z_k \\neq y_j ，那么， Z_k 是 X_i 与 Y_{j-1} 的一个最长公共子序列。注：此时 z_k 不一定等于 x_i ，但该推论是包含等于或不等于的情况的 根据以上推论可进一步推断以下求解过程是与其等效的： 当 x_i=y_j 时，首先找出 X_{i-1} 与 Y_{j-1} 的最长公共子序列，再在该子序列后面加上 x_i 或 y_j ，而后所得的子序列即为 X_i 与 Y_j 的最长公共子序列 而当 x_i \\neq y_j 时，就需要分别求解 X_{i-1} 与 Y_j 以及 X_i 与 Y_{j-1} 的最长公共子序列，最后，所得的这两个子序列中的较长者即为 X_i 与 Y_j 的最长公共子序列 若用 \\prod(i,j) 表示 X_i 与 Y_j 的最长公共子序列，那么，将有如下公式成立： \\prod(i,j) = \\begin{cases} \\prod(i-1,j-1) + x_i, & x_i = y_j \\\\ \\max\\big\\{ \\prod(i-1,j), \\prod(i,j-1) \\big\\}, & x_i \\neq y_j \\end{cases} , i \\geq 1, j \\geq 1 注意，公式中的加号表示序列与元素的连接，而不是数值的加减。当 i 与 j 为 1 时，上面的公式将出现 \\prod(0,0) ，而其正好表示的是 X_{i-1} 与 Y_{j-1} 的最长公共子序列为空序列，且其长度为 0 。 从以上公式可以发现最长公共子序列问题具有子问题重叠的性质。因为，在求解 X_i 与 Y_j 的最长公共子序列时，需要分别求解 X_{i-1} 与 Y_j 以及 X_i 与 Y_{j-1} 的最长公共子序列，而这两个子问题都包含一个公共子问题，即，求解 X_{i-1} 与 Y_{j-1} 的最长公共子序列。 因此，可以采用动态规划法来求解最长公共子序列问题。 动态规划在查找有很多重叠子问题的情况的最优解时有效。它将问题重新组合成子问题。为了避免多次解决这些子问题，它们的结果都逐渐被计算并被保存，从简单的问题直到整个问题都被解决。因此，动态规划保存递归时的结果，因而不会在解决同样的问题时花费时间。（引用自「维基百科」） 但是，若要寻找最长公共子序列，需要首先计算公共子序列的长度，再根据长度及坐标位置回溯才能寻找出 X_i 和 Y_j 的最长公共子序列。 因此，如果用二位数组 f[i][j] 表示序列 X_i 和 Y_j 的最长公共子序列的长度，那么根据前面的最长公共子序列的求解公式，便可相应地推导出求解最长公共子序列的长度的公式，即： f[i][j] = \\begin{cases} 0, & i = 0 或 j = 0 \\\\ f[i-1][j-1] + 1, & i \\geq 1, j \\geq 1 且 x_i = y_j \\\\ \\max\\big\\{ f[i-1][j], f[i][j-1] \\big\\}, & i \\geq 1, j \\geq 1 且 x_i \\neq y_j \\end{cases}这样， f[i][j] 中的最大值便是 X_i 和 Y_j 的最长公共子序列的长度，而根据该数组回溯，便可找到该最长公共子序列。 以序列 X_i=\\{ A, B, C, B, D, A, B \\} 和 Y_j=\\{ B, D, C, A, B, A \\} 为例，可以通过下图了解整个求解最长公共子序列长度的过程： 上图取自于 https://blog.csdn.net/v_JULY_v/article/details/6110269 这里直接给出实现代码，可以结合上图与代码进行分析（时间复杂度为 O(mn) ）： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051#define MAX_SEQ_LEN 50typedef enum &#123; LEN_DIR_LEFT, LEN_DIR_TOP, LEN_DIR_TOP_LEFT&#125; LCSLenDir;typedef struct _LCSLen &#123; // 最长公共子序列的长度 int value; // 长度求值基于哪个方向的结果， // 沿着该方向回溯便可反向找出对应的最长公共子序列 LCSLenDir dir;&#125; LCSLen;// Note：二维数组作为参数时，必须指定第二维的长度void lcs_search_dynamic_programming( LCSLen lcs_len[][MAX_SEQ_LEN] , int seq_x[], int seq_y[] , int seq_x_len, int seq_y_len) &#123; // 将(i,0)的单元格全部置为0 for (int i = 0; i &lt;= seq_x_len; i++) &#123; lcs_len[i][0].value = 0; &#125; // 将(0,j)的单元格全部置为0 for (int j = 0; j &lt;= seq_y_len; j++) &#123; lcs_len[0][j].value = 0; &#125; // 沿着二维数组的i轴从上到下依次沿着j轴从左到右计算公共子序列的长度 for (int i = 1; i &lt;= seq_x_len; i++) &#123; for (int j = 1; j &lt;= seq_y_len; j++) &#123; // f[i][j] = f[i-1][j-1] + 1, x[i] = y[j] // Note：数组seq_x与seq_y的元素是从0开始的 if (seq_x[i - 1] == seq_y[j - 1]) &#123; lcs_len[i][j].value = lcs_len[i - 1][j - 1].value + 1; lcs_len[i][j].dir = LEN_DIR_TOP_LEFT; &#125; // f[i][j] = max(f[i-1][j], f[i][j-1]) else if (lcs_len[i - 1][j].value &gt;= lcs_len[i][j - 1].value) &#123; lcs_len[i][j].value = lcs_len[i - 1][j].value; lcs_len[i][j].dir = LEN_DIR_TOP; &#125; else &#123; lcs_len[i][j].value = lcs_len[i][j - 1].value; lcs_len[i][j].dir = LEN_DIR_LEFT; &#125; &#125; &#125;&#125; 注意： 这里通过结构体LCSLen同时记录最长公共子序列的长度和方向，避免传递多个数组，可提升可读性 对于多个意义相同的固定的常量值，为其定义枚举类型，是一种良好的编码习惯 这里没有将i和j定义为函数的局部变量是为了在阅读时不用担心二者的值会被前面的逻辑所影响，因为前后的变量具有不同的作用域且是相互独立的。从而确保阅读的流畅性，同时，代码本身逻辑的内聚性也更强 需在确保良好的阅读体验的情况下对初始数据、方法参数列表等进行合理换行，避免在网页中出现横向滚动条，保证一眼可以看到全部内容 在得到最长公共子序列的长度的二维数组后，便可从最右下角位置开始回溯并打印最长公共子序列（时间复杂度为 O(m+n) ）： 123456789101112131415161718void print_lcs(LCSLen lcs_len[][MAX_SEQ_LEN], int seq_x[], int i, int j) &#123; if (i == 0 || j == 0) &#123; return; &#125; if (lcs_len[i][j].dir == LEN_DIR_TOP_LEFT) &#123; print_lcs(lcs_len, seq_x, i - 1, j - 1); // Note：i为序列X的下表， // 若要打印序列Y的元素，则应为 seq_y[j-1] printf(\"%c \", seq_x[i - 1]); &#125; else if(lcs_len[i][j].dir == LEN_DIR_TOP) &#123; print_lcs(lcs_len, seq_x, i - 1, j); &#125; else &#123; print_lcs(lcs_len, seq_x, i, j - 1); &#125;&#125; 参考 动态规划算法解最长公共子序列LCS问题：详细讲解了动态规划法的实现过程并给出了对空间复杂度进行优化后的实现代码 动态规划最长公共子序列过程图解：图例丰富有助于理解求解的动态过程 算法导论-最长公共子序列LCS（动态规划）：介绍了蛮力搜索和动态规划两种方式，也同样给出了进行空间优化后的代码（实现较前面的文章更简单、清晰）。注：蛮力搜索的时间复杂度为 O(n2^m) 附录以下为完整的各方案代码，并包含性能测试： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#define MAX_SEQ_LEN 50typedef enum &#123; LEN_DIR_LEFT, LEN_DIR_TOP, LEN_DIR_TOP_LEFT&#125; LCSLenDir;typedef struct _LCSLen &#123; // 最长公共子序列的长度 int value; // 长度求值基于哪个方向的结果， // 沿着该方向回溯便可反向找出对应的最长公共子序列 LCSLenDir dir;&#125; LCSLen;void print_lcs(LCSLen lcs_len[][MAX_SEQ_LEN], int seq_x[], int i, int j);void lcs_search_dynamic_programming( LCSLen lcs_len[][MAX_SEQ_LEN] , int seq_x[], int seq_y[] , int seq_x_len, int seq_y_len);int main(int argc, char *argv[]) &#123; int seq_x[] = &#123;'A', 'B', 'C', 'B', 'D', 'A', 'B'&#125;; // int seq_x[] = &#123;'A', 'C', 'C', 'G', 'G', 'T', 'C' // , 'G', 'A', 'G', 'T', 'G', 'C', 'G' // , 'C', 'G', 'G', 'A', 'A', 'G', 'C' // , 'C', 'G', 'G', 'C', 'C', 'G', 'A' // , 'A'&#125;; int seq_x_len = sizeof(seq_x) / sizeof(seq_x[0]); int seq_y[] = &#123;'B', 'D', 'C', 'A', 'B', 'A'&#125;; // int seq_y[] = &#123;'G', 'T', 'C', 'G', 'T', 'T', 'C' // , 'G', 'G', 'A', 'A', 'T', 'G', 'C' // , 'C', 'G', 'T', 'T', 'G', 'C', 'T' // , 'C', 'T', 'G', 'T', 'A', 'A', 'A'&#125;; int seq_y_len = sizeof(seq_y) / sizeof(seq_y[0]); LCSLen lcs_len[MAX_SEQ_LEN][MAX_SEQ_LEN]; lcs_search_dynamic_programming(lcs_len, seq_x, seq_y, seq_x_len, seq_y_len); printf(\"最长公共子序列的长度为: %d\\n\", lcs_len[seq_x_len][seq_y_len].value); printf(\"其中一个最长公共子序列为: \"); print_lcs(lcs_len, seq_x, seq_x_len, seq_y_len); printf(\"\\n\"); return 0;&#125;// Note：二维数组作为参数时，必须指定第二维的长度void lcs_search_dynamic_programming( LCSLen lcs_len[][MAX_SEQ_LEN] , int seq_x[], int seq_y[] , int seq_x_len, int seq_y_len) &#123; // 将(i,0)的单元格全部置为0 for (int i = 0; i &lt;= seq_x_len; i++) &#123; lcs_len[i][0].value = 0; &#125; // 将(0,j)的单元格全部置为0 for (int j = 0; j &lt;= seq_y_len; j++) &#123; lcs_len[0][j].value = 0; &#125; // 沿着二维数组的i轴从上到下依次沿着j轴从左到右计算公共子序列的长度 for (int i = 1; i &lt;= seq_x_len; i++) &#123; for (int j = 1; j &lt;= seq_y_len; j++) &#123; // f[i][j] = f[i-1][j-1] + 1, x[i] = y[j] // Note：数组seq_x与seq_y的元素是从0开始的 if (seq_x[i - 1] == seq_y[j - 1]) &#123; lcs_len[i][j].value = lcs_len[i - 1][j - 1].value + 1; lcs_len[i][j].dir = LEN_DIR_TOP_LEFT; &#125; // f[i][j] = max(f[i-1][j], f[i][j-1]) else if (lcs_len[i - 1][j].value &gt;= lcs_len[i][j - 1].value) &#123; lcs_len[i][j].value = lcs_len[i - 1][j].value; lcs_len[i][j].dir = LEN_DIR_TOP; &#125; else &#123; lcs_len[i][j].value = lcs_len[i][j - 1].value; lcs_len[i][j].dir = LEN_DIR_LEFT; &#125; &#125; &#125;&#125;void print_lcs(LCSLen lcs_len[][MAX_SEQ_LEN], int seq_x[], int i, int j) &#123; if (i == 0 || j == 0) &#123; return; &#125; if (lcs_len[i][j].dir == LEN_DIR_TOP_LEFT) &#123; print_lcs(lcs_len, seq_x, i - 1, j - 1); // Note：i为序列X的下表， // 若要打印序列Y的元素，则应为 seq_y[j-1] printf(\"%c \", seq_x[i - 1]); &#125; else if(lcs_len[i][j].dir == LEN_DIR_TOP) &#123; print_lcs(lcs_len, seq_x, i - 1, j); &#125; else &#123; print_lcs(lcs_len, seq_x, i, j - 1); &#125;&#125;"},{"title":"算法分析：求解最大子段和","permalink":"https://flytreeleft.github.io/algorithm-calculating-maximum-interval-sum/","text":"算法分析系列文章中的代码可被任何人无偿使用于任何场景且无需注明来源也不必在使用前征得本文作者同意。 算法分析系列文章旨在传播准确、完整、简洁、易懂、规范的代码实现，并传授基本的编程思想和良好的编码习惯与技巧。 若文章中的代码存在问题或逻辑错误，请通过邮件等形式（见文章结尾）告知于本文作者以便及时修正错误或改进代码。 算法系列文章不可避免地会参考和学习众多网友的成果，在行文风格、内容及求解思路上也会进行借鉴，如有侵权嫌疑，请联系本文作者。 PS：若为转载该文章，请务必注明来源，本站点欢迎大家转载。 问题描述给定一个整数（正负数不限）序列 $a_1, a_2, a_3, …, a_n$ ，从该序列中选取任意相邻的一段求和（简称为「子段和」），求解该序列的最大子段和。注：若整个序列的所有元素均为负数，则其最大子段和固定为0。 例如，序列[64, -24, 88, -39, -54, 16]的最大子段和为128（= 64 + (-24) + 88）。 求解方案穷举法穷举法就是从 $a_0$ 开始依次计算 a_0, a_0 + a_1, a_0 + a_1 + a_2, a_0 + a_1 + ... + a_n 并取其中的最大值，再从 $a_1$ 开始依次计算 a_1, a_1 + a_2, a_1 + a_2 + ... + a_n 并取其中的最大值，以此往复，直到 $a_n$ 为止，并取每次计算过程中的最大值，得到的最终结果即为所求。 该穷举过程用代码实现即为： 123456789101112131415161718192021222324252627282930typedef struct _SubseqSum &#123; int value; // 序列区间求和后的值 int start; // 求和区间的开始位置 int end; // 求和区间的结束位置&#125; SubseqSum;SubseqSum max_subseq_sum_force(int seq[], int seq_len) &#123; SubseqSum max_sum = &#123; .value = 0, .start = 0, .end = 0 &#125;; int max_sum_value = 0; for (int i = 0; i &lt; seq_len; i++) &#123; for (int j = i; j &lt; seq_len; j++) &#123; // 计算从i到j这个区间的和 int sum_value = 0; for (int k = i; k &lt;= j; k++) &#123; sum_value += seq[k]; &#125; // 当i到j的区间的和大于当前已记录的最大子段和时，更新该最大子段和为该区间的和 if (sum_value &gt; max_sum_value) &#123; max_sum_value = sum_value; // 更新最大子段和的结果及其求和区间 max_sum.value = max_sum_value; max_sum.start = i; max_sum.end = j; &#125; &#125; &#125; return max_sum;&#125; 注意： 这里定义了结构体SubseqSum用于同时记录子段和及其求和区间，可便于对最终结果进行人工复查以验证代码的正确性 在for、if ... else ...等分支中即使仅有一行代码，甚至没有代码（如，while (true) {}），也不要省略花括号（{}），这是避免代码混乱、提升代码可读性和准确性的前提 通过指针类型的参数来获取函数内部的过程数据（如，int max_subseq_sum(int seq[], int seq_len, int &amp;begin, int &amp;end) {...}）的方式不是一种良好的编码习惯。虽然，许多编程语言的函数不支持返回多值，但通过结构体等方式可以更好地达到目的（甚至好于返回多值），最终的代码也会更易阅读和理解 本例用到了三层循环，其时间复杂度为 $O(n^3)$ 。但仔细分析后可以发现，在第三层循环中，从 $i$ 到 $j$ 区间的和会被重复计算多次，即，存在计算序列 a_i, a_i + a_{i+1}, a_i + a_{i+1} + a_{i+2}, a_i + a_{i+1} + ... + a_{j-1} + a_j ，而实际上， a_i + ... + a_{j-1} 已经被计算过了，没有必要再重复计算，若将其存放在变量 $tmp$ 中（即， tmp = a_i + a_{i+1} + ... + a_{j-1} ），则计算 a_i + a_{i+1} + ... + a_{j-1} + a_j 的值，等效于计算 tmp + a_j 的值。 按照以上思路，可将上面的穷举实现改进为如下代码（时间复杂度为 $O(n^2)$ ）： 1234567891011121314151617181920212223242526272829typedef struct _SubseqSum &#123; int value; // 序列区间求和后的值 int start; // 求和区间的开始位置 int end; // 求和区间的结束位置&#125; SubseqSum;SubseqSum max_subseq_sum_force_adv(int seq[], int seq_len) &#123; SubseqSum max_sum = &#123; .value = 0, .start = 0, .end = 0 &#125;; int max_sum_value = 0; for (int i = 0; i &lt; seq_len; i++) &#123; // 通过sum_value记录从i到j-1这个区间的和， // 当求解i到j区间的和时，其便等效于sum_value+seq[j] int sum_value = 0; for (int j = i; j &lt; seq_len; j++) &#123; sum_value += seq[j]; if (sum_value &gt; max_sum_value) &#123; max_sum_value = sum_value; // 更新最大子段和的结果及其求和区间 max_sum.value = max_sum_value; max_sum.start = i; max_sum.end = j; &#125; &#125; &#125; return max_sum;&#125; 分治法 分治法，即，把一个复杂的问题分成两个或更多的相同或相似的子问题，直到最后子问题可以简单的直接求解，原问题的解即子问题的解的合并。（引用自「维基百科」） 通过分治法的思想，可以将序列 a_1, a_2, ..., a_n 等分为两部分，即， a_1, a_2, ..., a_{\\frac{n}{2}} （称为左子序列） 与 a_{\\frac{n}{2}+1}, a_{\\frac{n}{2}+2}, ..., a_n （称为右子序列） 两个子序列，再分别求解这两个子序列的最大子段和。最终原序列的最大子段和的求解便存在以下情况： 原序列的最大子段和等于左子序列的最大子段和 原序列的最大子段和等于右子序列的最大子段和 原序列的最大子段和为 \\sum_{k=i}^{j} a_k ，其中， 1 \\leq i \\leq \\frac{n}{2}, \\frac{n}{2}+1 \\leq j \\leq n 前两种情况通过递归可以得到结果，而对于第三种情况，可以从 $\\frac{n}{2}$ 和 $\\frac{n}{2}+1$ 开始分别向左右两边求和，即，定义如下表达式： \\begin{align} s1 &= \\max_{1 \\leq i \\leq \\frac{n}{2}} \\bigg\\{ \\sum_{k=\\frac{n}{2}}^{i} a_k \\bigg\\} & \\Leftrightarrow s1 &= \\max\\bigg\\{ a_{\\frac{n}{2}}, a_{\\frac{n}{2}} + a_{\\frac{n}{2}-1}, ..., a_{\\frac{n}{2}} + a_{\\frac{n}{2}-1} + ... + a_2 + a_1 \\bigg\\}, i=i-1 \\rightarrow 1 \\\\ s2 &= \\max_{\\frac{n}{2}+1 \\leq j \\leq n} \\bigg\\{ \\sum_{k=\\frac{n}{2}+1}^{j} a_k \\bigg\\} & \\Leftrightarrow s2 &= \\max\\bigg\\{ a_{\\frac{n}{2}+1}, a_{\\frac{n}{2}+1} + a_{\\frac{n}{2}+2}, ..., a_{\\frac{n}{2}+1} + a_{\\frac{n}{2}+2} + ... + a_{n-1} + a_n \\bigg\\}, j=j+1 \\rightarrow n \\end{align}则 s1+s2 即为第三种情况的最优解。注意，为了准确传达出向左右两边推进求和的过程，这里对求和公式做了变换，让 $k$ 始终从中间位置（即 \\frac{n}{2} 和 \\frac{n}{2}+1 处）开始向 i 递减或向 j 递增。 根据以上分析可编写其实现代码为（时间复杂度为 $O(n\\log n)$ ）： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293typedef struct _SubseqSum &#123; int value; // 序列区间求和后的值 int start; // 求和区间的开始位置 int end; // 求和区间的结束位置&#125; SubseqSum;int max(int num0, int num1) &#123; return num0 &gt; num1 ? num0 : num1;&#125;SubseqSum max_subseq_sum_divide(int seq[], int left, int right) &#123; if (left == right) &#123; return (SubseqSum) &#123; .value = max(0, seq[left]), .start = left, .end = left &#125;; &#125; int center = (left + right) / 2; // 计算左边区间的最大子段和 SubseqSum left_max_sum = max_subseq_sum_divide(seq, left, center); // 计算右边区间的最大子段和 SubseqSum right_max_sum = max_subseq_sum_divide(seq, center + 1, right); // 计算从中间位置向左右区间的最大子段和 SubseqSum center_max_sum = max_subseq_sum_divide_for_center(seq, center, left, right); // 三个部分的最大结果即为所求的最大子段和 SubseqSum max_sum = center_max_sum; if(max_sum.value &lt; left_max_sum.value) &#123; max_sum = left_max_sum; &#125; if(max_sum.value &lt; right_max_sum.value) &#123; max_sum = right_max_sum; &#125; return max_sum;&#125;// 从中间位置开始对该位置左右两边子段进行求和SubseqSum max_subseq_sum_divide_for_center(int seq[], int center, int left, int right) &#123; SubseqSum max_sum = &#123; .value = 0, .start = center, .end = center &#125;; // [left, ..., center, center + 1, ..., right] // &lt;-- i j --&gt; // 先从center开始向左推进以计算左边子段求和的最大值： // - i记录的是左边求和区间的左边界（右边界为center） // - 只有求和结果（left_sum_value）大于0才会推进 int left_sum_value = 0; int left_max_sum_value = 0; for (int i = center; i &gt;= left; i--) &#123; left_sum_value += seq[i]; if (left_sum_value &gt; left_max_sum_value) &#123; left_max_sum_value = left_sum_value; max_sum.start = i; &#125; &#125; // 再从center+1开始向右推进以计算右边子段求和的最大值： // - j记录的是右边求和区间的右边界（左边界为center+1） // - 只有求和结果（right_sum_value）大于0才会推进 int right_sum_value = 0; int right_max_sum_value = 0; for(int j = center + 1; j &lt;= right; j++) &#123; right_sum_value += seq[j]; if(right_sum_value &gt; right_max_sum_value) &#123; right_max_sum_value = right_sum_value; max_sum.end = j; &#125; &#125; // 最后所求的子段和为左右两个子段的 最大求和值 之和 int max_sum_value = left_max_sum_value + right_max_sum_value; max_sum.value = max_sum_value; // 子段求和未向左推进（向左求和的结果依然为0）但向右推进（向右求和的结果大于0）了， // 则表示求和区间应该从右边开始 if (left_max_sum_value == 0 &amp;&amp; right_max_sum_value &gt; 0) &#123; max_sum.start = center + 1; &#125; // 子段求和未向右推进（向右求和的结果依然为0）但向左推进（向左求和的结果大于0）了， // 则表示求和区间应该从左边开始 if (right_max_sum_value == 0 &amp;&amp; left_max_sum_value &gt; 0) &#123; max_sum.end = center; &#125; // 而若向左/向右均没有推进，则保持原地不动 if (left_max_sum_value == 0 &amp;&amp; right_max_sum_value == 0) &#123; max_sum.start = max_sum.end = center; &#125; return max_sum;&#125; 注意： 在实现代码中将上面提到的第三种情况提取出来以便对该特例进行独立分析，也避免了对前面的主过程的阅读和分析造成的干扰 在max_subseq_sum_divide_for_center的最后需要对求和区间的起止位置进行修正，具体内容见代码注释 动态规划法在应用该方法之前，先来看看其数学的推导过程。 假设存在序列 $a_1, a_2, a_3, …, a_n$ ，记 $b_j$ 表示该序列从 $1$ 到 $j$ 的区间内的最大子段和，则其可用如下公式表示： b_j = \\max_{1 \\leq i \\leq j} \\bigg\\{ \\sum_{k=i}^{j} a_k \\bigg\\}, 1 \\leq j \\leq n也就是以下等式成立： \\begin{align} b_1 &= a_1 \\\\ b_2 &= \\max\\{ a_1 + a_2, a_2 \\} \\\\ b_3 &= \\max\\{ a_1 + a_2 + a_3, a_2 + a_3, a_3 \\} \\end{align}因此，求解整个序列的最大子段和 $F(n)$ 的数学公式即为： F(n) = \\max_{1 \\leq i \\leq j \\leq n} \\bigg\\{ \\sum_{k=i}^{j} a_k \\bigg\\} = \\max_{1 \\leq j \\leq n} \\Bigg\\{ \\max_{1 \\leq i \\leq j} \\bigg\\{ \\sum_{k=i}^{j} a_k \\bigg\\} \\Bigg\\} = \\max_{1 \\leq j \\leq n}\\{ b_j \\}也就是说，要求解整个序列的最大子段和，可以转化为计算从 $1$ 到 $n$ 的区间内的 $b_j$ （ $1 \\leq j \\leq n$ ） 的最大值。 而 $b_j$ 可以用递归表达式表示为： b_j = \\max\\{ b_{j - 1} + a_j, a_j \\}, 1 \\leq j \\leq n但是，当 b_{j-1} 小于等于0时，无论 a_j 为正还是负，最终 b_{j-1}+a_j 都将小于 a_j ，这时将有 b_j=a_j 成立，因此，最终 b_j 可表示为： b_j = \\begin{cases} b_{j - 1} + a_j, & b_{j - 1} > 0 \\\\ a_j, & b_{j - 1} \\leq 0 \\end{cases} , 1 \\leq j \\leq n以上推导过程需要仔细阅读和分析，在完全掌握该推导过程后，便可很容易编写出对应的求解代码（时间复杂度为 $O(n)$ ），即： 123456789101112131415161718192021222324252627282930313233343536373839404142434445#define MAX_SEQ_LEN 1000typedef struct _SubseqSum &#123; int value; // 序列区间求和后的值 int start; // 求和区间的开始位置 int end; // 求和区间的结束位置&#125; SubseqSum;int max(int num0, int num1) &#123; return num0 &gt; num1 ? num0 : num1;&#125;SubseqSum max_subseq_sum_dynamic_programming(int seq[], int seq_len) &#123; // 求和序列：存放子段求和的中间结果，开始元素为传入序列的第0项 int seq_sum[MAX_SEQ_LEN] = &#123; seq[0] &#125;; SubseqSum max_sum = &#123; .value = max(0, seq_sum[0]), .start = 0, .end = 0 &#125;; int max_sum_value = 0; int expected_sum_start = 0; for(int j = 1; j &lt; seq_len; j++) &#123; // 向左看，若前面已计算的子段和大于0，则加上当前项后，可能会得到更大的子段和， // 即对应公式中的“b[j] = b[j-1] + a[j]”分支 if (seq_sum[j - 1] &gt; 0) &#123; seq_sum[j] = seq_sum[j - 1] + seq[j]; &#125; // 而若前面已计算的子段和小于0，则丢弃该结果，从当前位置开始重新计算子段和， // 即对应公式中的“b[j] = a[j]”分支 else &#123; seq_sum[j] = seq[j]; // 但新的子段和不一定大于当前已得到的最大子段和， // 故，需临时存放该新子段的开始位置，待最大子段和被更新后再更新其所在的子段区间 expected_sum_start = j; &#125; // 这里取公式中的“b[j]”的最大值 if (seq_sum[j] &gt; max_sum_value) &#123; max_sum_value = seq_sum[j]; // 应用新的子段和，并更新该子段的开始和结束位置 max_sum.value = max_sum_value; max_sum.start = expected_sum_start; max_sum.end = j; &#125; &#125; return max_sum;&#125; 参考 最大子段和问题总结：涉及穷举法、分治法、动态规划法及改进 动态规划之最大子段和：对动态规划法的公式讲解较为详细 最大子段和(分治与动态规划典例)：对分治法讲解较为详细 附录以下为完整的各方案代码，并包含性能测试： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;sys/time.h&gt; // for gettimeofday()#include &lt;time.h&gt; // for time()#define MAX_SEQ_LEN 1000typedef struct _SubseqSum &#123; int value; // 序列区间求和后的值 int start; // 求和区间的开始位置 int end; // 求和区间的结束位置&#125; SubseqSum;double current_timestamp();int max(int num0, int num1);void init_random_sequence(int seq[], int len);void print_sequence(int seq[], int len);int sum_subseq(int seq[], int start, int end);SubseqSum max_subseq_sum_force(int seq[], int seq_len);SubseqSum max_subseq_sum_force_adv(int seq[], int seq_len);SubseqSum max_subseq_sum_divide(int seq[], int left, int right);SubseqSum max_subseq_sum_divide_for_center(int seq[], int center, int left, int right);SubseqSum max_subseq_sum_dynamic_programming(int seq[], int seq_len);int main(int argc, char *argv[]) &#123; int seq_len = 50; int seq[MAX_SEQ_LEN]; init_random_sequence(seq, seq_len); // int seq[] = &#123;-31, 95, 62, -45, 13, 31, -77 // , 22, 94, -65, -67, 50, -66, 28 // , -98, -34, -97, -66, -84, 87, 32 // , -28, 43, -75, -64, 24, 88, 39 // , -54, -16, 89, 82, -81, 45, 61 // , -62, -51, -4, -41, -32, -21, -37 // , 32, 63, -44, -39, -30, -19, 71 // , 77&#125;; // int seq[] = &#123;-5, 11, -4, 13, -4, -2&#125;; // int seq[] = &#123;0, 0, 0, 0, 0, 0&#125;; // 不同方法得到的求和区间会不同 // int seq_len = sizeof(seq) / sizeof(seq[0]); SubseqSum max_sum; double start_time, end_time; print_sequence(seq, seq_len); printf(\"\\n以上序列的最大子段和为:\\n\"); start_time = current_timestamp(); max_sum = max_subseq_sum_force(seq, seq_len); end_time = current_timestamp(); printf(\"- 穷举算法 : %d (求和区间: [%d, %d] +=&gt;&gt; %d), 耗时: %f毫秒\\n\" , max_sum.value , max_sum.start, max_sum.end , sum_subseq(seq, max_sum.start, max_sum.end) , end_time - start_time); start_time = current_timestamp(); max_sum = max_subseq_sum_force_adv(seq, seq_len); end_time = current_timestamp(); printf(\"- 穷举算法(改进版): %d (求和区间: [%d, %d] +=&gt;&gt; %d), 耗时: %f毫秒\\n\" , max_sum.value , max_sum.start, max_sum.end , sum_subseq(seq, max_sum.start, max_sum.end) , end_time - start_time); start_time = current_timestamp(); max_sum = max_subseq_sum_divide(seq, 0, seq_len - 1); end_time = current_timestamp(); printf(\"- 分治算法 : %d (求和区间: [%d, %d] +=&gt;&gt; %d), 耗时: %f毫秒\\n\" , max_sum.value , max_sum.start, max_sum.end , sum_subseq(seq, max_sum.start, max_sum.end) , end_time - start_time); start_time = current_timestamp(); max_sum = max_subseq_sum_dynamic_programming(seq, seq_len); end_time = current_timestamp(); printf(\"- 动态规划算法 : %d (求和区间: [%d, %d] +=&gt;&gt; %d), 耗时: %f毫秒\\n\" , max_sum.value , max_sum.start, max_sum.end , sum_subseq(seq, max_sum.start, max_sum.end) , end_time - start_time); return 0;&#125;// 穷举（蛮力）法求解SubseqSum max_subseq_sum_force(int seq[], int seq_len) &#123; SubseqSum max_sum = &#123; .value = 0, .start = 0, .end = 0 &#125;; int max_sum_value = 0; for (int i = 0; i &lt; seq_len; i++) &#123; for (int j = i; j &lt; seq_len; j++) &#123; // 计算从i到j这个区间的和 int sum_value = 0; for (int k = i; k &lt;= j; k++) &#123; sum_value += seq[k]; &#125; // 当i到j的区间的和大于当前已记录的最大子段和时，更新该最大子段和为该区间的和 if (sum_value &gt; max_sum_value) &#123; max_sum_value = sum_value; // 更新最大子段和的结果及其求和区间 max_sum.value = max_sum_value; max_sum.start = i; max_sum.end = j; &#125; &#125; &#125; return max_sum;&#125;// 穷举法（改进版）求解SubseqSum max_subseq_sum_force_adv(int seq[], int seq_len) &#123; SubseqSum max_sum = &#123; .value = 0, .start = 0, .end = 0 &#125;; int max_sum_value = 0; for (int i = 0; i &lt; seq_len; i++) &#123; // 通过sum_value记录从i到j-1这个区间的和， // 当求解i到j区间的和时，其便等效于sum_value+seq[j] int sum_value = 0; for (int j = i; j &lt; seq_len; j++) &#123; sum_value += seq[j]; if (sum_value &gt; max_sum_value) &#123; max_sum_value = sum_value; // 更新最大子段和的结果及其求和区间 max_sum.value = max_sum_value; max_sum.start = i; max_sum.end = j; &#125; &#125; &#125; return max_sum;&#125;// 分治法求解SubseqSum max_subseq_sum_divide(int seq[], int left, int right) &#123; if (left == right) &#123; return (SubseqSum) &#123; .value = max(0, seq[left]), .start = left, .end = left &#125;; &#125; int center = (left + right) / 2; // 计算左边区间的最大子段和 SubseqSum left_max_sum = max_subseq_sum_divide(seq, left, center); // 计算右边区间的最大子段和 SubseqSum right_max_sum = max_subseq_sum_divide(seq, center + 1, right); // 计算从中间位置向左右区间的最大子段和 SubseqSum center_max_sum = max_subseq_sum_divide_for_center(seq, center, left, right); // 三个部分的最大结果即为所求的最大子段和 SubseqSum max_sum = center_max_sum; if(max_sum.value &lt; left_max_sum.value) &#123; max_sum = left_max_sum; &#125; if(max_sum.value &lt; right_max_sum.value) &#123; max_sum = right_max_sum; &#125; return max_sum;&#125;// 分治法求解：从中间位置开始对该位置左右两边子段进行求和SubseqSum max_subseq_sum_divide_for_center(int seq[], int center, int left, int right) &#123; SubseqSum max_sum = &#123; .value = 0, .start = center, .end = center &#125;; // [left, ..., center, center + 1, ..., right] // &lt;-- i j --&gt; // 先从center开始向左推进以计算左边子段求和的最大值： // - i记录的是左边求和区间的左边界（右边界为center） // - 只有求和结果（left_sum_value）大于0才会推进 int left_sum_value = 0; int left_max_sum_value = 0; for (int i = center; i &gt;= left; i--) &#123; left_sum_value += seq[i]; if (left_sum_value &gt; left_max_sum_value) &#123; left_max_sum_value = left_sum_value; max_sum.start = i; &#125; &#125; // 再从center+1开始向右推进以计算右边子段求和的最大值： // - j记录的是右边求和区间的右边界（左边界为center+1） // - 只有求和结果（right_sum_value）大于0才会推进 int right_sum_value = 0; int right_max_sum_value = 0; for(int j = center + 1; j &lt;= right; j++) &#123; right_sum_value += seq[j]; if(right_sum_value &gt; right_max_sum_value) &#123; right_max_sum_value = right_sum_value; max_sum.end = j; &#125; &#125; // 最后所求的子段和为左右两个子段的 最大求和值 之和 int max_sum_value = left_max_sum_value + right_max_sum_value; max_sum.value = max_sum_value; // 子段求和未向左推进（向左求和的结果依然为0）但向右推进（向右求和的结果大于0）了， // 则表示求和区间应该从右边开始 if (left_max_sum_value == 0 &amp;&amp; right_max_sum_value &gt; 0) &#123; max_sum.start = center + 1; &#125; // 子段求和未向右推进（向右求和的结果依然为0）但向左推进（向左求和的结果大于0）了， // 则表示求和区间应该从左边开始 if (right_max_sum_value == 0 &amp;&amp; left_max_sum_value &gt; 0) &#123; max_sum.end = center; &#125; // 而若向左/向右均没有推进，则保持原地不动 if (left_max_sum_value == 0 &amp;&amp; right_max_sum_value == 0) &#123; max_sum.start = max_sum.end = center; &#125; return max_sum;&#125;// 动态规划法求解SubseqSum max_subseq_sum_dynamic_programming(int seq[], int seq_len) &#123; // 求和序列：存放子段求和的中间结果，开始元素为传入序列的第0项 int seq_sum[MAX_SEQ_LEN] = &#123; seq[0] &#125;; SubseqSum max_sum = &#123; .value = max(0, seq_sum[0]), .start = 0, .end = 0 &#125;; int max_sum_value = 0; int expected_sum_start = 0; for(int j = 1; j &lt; seq_len; j++) &#123; // 向左看，若前面已计算的子段和大于0，则加上当前项后，可能会得到更大的子段和， // 即对应公式中的“b[j] = b[j-1] + a[j]”分支 if (seq_sum[j - 1] &gt; 0) &#123; seq_sum[j] = seq_sum[j - 1] + seq[j]; &#125; // 而若前面已计算的子段和小于0，则丢弃该结果，从当前位置开始重新计算子段和， // 即对应公式中的“b[j] = a[j]”分支 else &#123; seq_sum[j] = seq[j]; // 但新的子段和不一定大于当前已得到的最大子段和， // 故，需临时存放该新子段的开始位置，待最大子段和被更新后再更新其所在的子段区间 expected_sum_start = j; &#125; // 这里取公式中的“b[j]”的最大值 if (seq_sum[j] &gt; max_sum_value) &#123; max_sum_value = seq_sum[j]; // 应用新的子段和，并更新该子段的开始和结束位置 max_sum.value = max_sum_value; max_sum.start = expected_sum_start; max_sum.end = j; &#125; &#125; return max_sum;&#125;int max(int num0, int num1) &#123; return num0 &gt; num1 ? num0 : num1;&#125;// 获取当前系统时间的毫秒值double current_timestamp() &#123; struct timeval te; gettimeofday(&amp;te, NULL); double msec = te.tv_sec * 1000.0 + (te.tv_usec / 1000.0); return msec;&#125;void init_random_sequence(int seq[], int len) &#123; // https://www.geeksforgeeks.org/rand-and-srand-in-ccpp/ srand(time(0)); for (int i = 0; i &lt; len; i++) &#123; // 取0-100之间的数并随机产生正负 seq[i] = (int) (rand() * 1.0 / RAND_MAX * 100) * (rand() % 2 == 0 ? 1 : -1); &#125;&#125;void print_sequence(int seq[], int len) &#123; int columns = 10; for (int i = 0; i &lt; len; i++) &#123; printf(\"%3d: %3d, \", i, seq[i]); if ((i + 1) % columns == 0 &amp;&amp; i &lt; len - 1) &#123; printf(\"\\n\"); &#125; &#125;&#125;int sum_subseq(int seq[], int start, int end) &#123; int sum = 0; for (int i = (start &lt; end ? start : end); i &lt;= (end &gt; start ? end : start); i++) &#123; sum += seq[i]; &#125; return sum;&#125;"},{"title":"算法分析：求解斐波那契数列","permalink":"https://flytreeleft.github.io/algorithm-calculating-fibonacci-numbers/","text":"算法分析系列文章中的代码可被任何人无偿使用于任何场景且无需注明来源也不必在使用前征得本文作者同意。 算法分析系列文章旨在传播准确、完整、简洁、易懂、规范的代码实现，并传授基本的编程思想和良好的编码习惯与技巧。 若文章中的代码存在问题或逻辑错误，请通过邮件等形式（见文章结尾）告知于本文作者以便及时修正错误或改进代码。 算法系列文章不可避免地会参考和学习众多网友的成果，在行文风格、内容及求解思路上也会进行借鉴，如有侵权嫌疑，请联系本文作者。 PS：若为转载该文章，请务必注明来源，本站点欢迎大家转载。 问题描述从0和1开始，之后的每一个数均为前两个数的和，这样性质的数依次排列，便称为斐波那契数列。即形成如下数列形式： 10, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, ... 用数学公式表示该数列即为： F(n) = \\begin{cases} 0, & n = 0 \\\\ 1, & n = 1 \\\\ F(n - 1) + F(n - 2), & n >= 2 \\end{cases}本案例所要解决的就是：给定一个整数n，求解斐波那契数列中第n项的数值。注意，0表示第零项，而不是第一项。 求解方案递归法从斐波那契数列的数学公式可以很直观地想到通过递归方法来求解（这里仅为代码片断，详细的见附录）： 12345678uint64_t fibonacci_recursion(uint32_t n) &#123; if (n == 0) &#123; return 0; &#125; else if (n == 1) &#123; return 1; &#125; return fibonacci_recursion(n - 1) + fibonacci_recursion(n - 2);&#125; 注意： 这里定义数列的数值为uint64_t类型，其所能表示的最大值大于int类型的数据，从而便于计算更大长度的数列 以上递归过程可以用下图展示（以n=9为例）： Show graph description @startdot digraph G { f9 [label=\"F(9)\"] f9_f8 [label=\"F(8)\"] f9_f7 [label=\"F(7)\"] f9_f8_f7 [label=\"F(7)\"] f9_f8_f6 [label=\"F(6)\"] f9_f7_f6 [label=\"F(6)\"] f9_f7_f5 [label=\"F(5)\"] f9_f8_f7_f6 [label=\"F(6)\"] f9_f8_f7_f5 [label=\"F(5)\"] f9_f8_f7_f6_f5 [label=\"F(5)\"] f9_f8_f7_f6_f4 [label=\"F(4)\"] f9 -> f9_f8 f9 -> f9_f7 f9_f8 -> f9_f8_f7 f9_f8 -> f9_f8_f6 f9_f7 -> f9_f7_f6 f9_f7 -> f9_f7_f5 f9_f8_f7 -> f9_f8_f7_f6 f9_f8_f7 -> f9_f8_f7_f5 f9_f8_f7_f6 -> f9_f8_f7_f6_f5 f9_f8_f7_f6 -> f9_f8_f7_f6_f4 } @enddot 从上图可以看出来，整个过程就是在计算二叉树的根节点的数值（=左节点数值+右节点数值）。遍历所有节点的时间复杂度为 $O(2^n)$ ，该时间复杂度也就是递归的时间复杂度。 动态规划法从以上递归方案可以发现，在计算过程中出现了大量的重复计算，比如，在计算F(9)时需要计算F(8)与F(7)，而计算F(8)时，又要重新计算F(7)。而如果我们将F(7)的计算结果保留下来，则当F(8)计算完毕后，便可直接通过记录下来的F(7)与F(8)求和得到F(9)的结果。也就免去了对二叉树右子树的遍历过程，只需要自顶向下一直沿着左子树做遍历即可，所需时间为二叉树的高度n，时间复杂度也就变为 $O(n)$ 。 而对于包含重复求解的过程，采用动态规划法可以很好地避免该问题。 动态规划在查找有很多重叠子问题的情况的最优解时有效。它将问题重新组合成子问题。为了避免多次解决这些子问题，它们的结果都逐渐被计算并被保存，从简单的问题直到整个问题都被解决。因此，动态规划保存递归时的结果，因而不会在解决同样的问题时花费时间。（引用自「维基百科」） 以下为采用动态规划法的求解代码： 12345678910111213141516171819202122// uint64_t所能表示的最大整数为18446744073709551615,// 而数列的第94项将大于该数，故，这里限定最大只能求解第93项的数值，// 不过，由于数组索引为0的位置表示的为数列的第0项，故，数组的实际长度应为n+1，// 而索引位置为n的元素即为数列的第n项数值#define MAX_FIBONACCI_SIZE 94uint64_t fibonacci_dynamic_programming(uint32_t n) &#123; static uint64_t fibonacci[MAX_FIBONACCI_SIZE] = &#123;0, 1&#125;; if (n == 0) &#123; return 0; &#125; // 数列的第n项不为0时，便可认定为已经计算过该项的值，直接返回，无需继续计算 else if (fibonacci[n] != 0) &#123; return fibonacci[n]; &#125; // 按照数列的数据公式递归求解第n项的值，并将其记录在数组中，这样，在左递归完成后，便不会再继续右递归了 else &#123; fibonacci[n] = fibonacci_dynamic_programming(n - 1) + fibonacci_dynamic_programming(n - 2); return fibonacci[n]; &#125;&#125; 注意： 这里采用C语言中的静态局部变量（fibonacci）来记录过程数据，可避免从外部传递数组，以提高接口的内聚性。若需要打印数列的所有项的数值，则可从外部传入数组，再将各项结果存储在该数组中，最后按序打印即可 迭代法 可能有同学会将该方法视为动态规划法的迭代版本，但是，本文却不是很赞同。 虽然，在该迭代过程中有存储数列前一项的计算结果，但其与动态规划存在的一个不同是，动态规划中所存储的计算结果不是立即被使用的，其是在遇到对相同项求值时才被调用的，且对其也可能存在多次调用的情况，而迭代过程中的计算结果只会被使用一次而且是立即使用。 所以，本文将这两种视为不同且独立的方法。 其实，如果不考虑数学公式所造成的误导性以及对相关算法的学习的角度，而仅从对数列的描述来看，最直接的求解方法应该是迭代（即，循环）方式。因为，从第2项开始，数列的每项数值均为前两项的和。用代码表示即为： 123456789101112131415161718192021222324252627282930313233uint64_t fibonacci_loop(uint32_t n) &#123; if (n == 0) &#123; return 0; &#125; else if (n == 1) &#123; return 1; &#125; else &#123; // 数列的第n项 uint64_t fib_n = 0; // 数列的第n-1项，初始为第1项，值为1 uint64_t fib_n_1 = 1; // 数列的第n-2项，初始为第0项，值为0 uint64_t fib_n_2 = 0; // 开始状态： // [...................n_2....n_1...n.....] // | | | // [0, 1, 1, 2, 3, 5, n - 2, n - 1, n, ...] // 向右平移后： // [.........................n_2...n_1..n.] // | | // [0, 1, 1, 2, 3, 5, n - 2, n - 1, n, ...] for (uint32_t i = 2; i &lt;= n; i++) &#123; // 数列的第n项 = 数列的第n-1项 + 数列的第n-2项 fib_n = fib_n_1 + fib_n_2; // 向右平移1项，即， // 上一次计算的第n-1项作为下一次计算的第n-2项， // 上一次计算的第n项作为下一次计算的第n-1项 fib_n_2 = fib_n_1; fib_n_1 = fib_n; &#125; return fib_n; &#125;&#125; 从时间复杂度来看，该方法与动态规划法是一样的，二者的时间复杂度均为 $O(n)$ ，只是，从代码性能来看，迭代方式的空间复杂度为 $O(1)$ ，而且，由于递归需要消耗内存的栈空间并且调用过程中存在变量入栈出栈操作，因此，递归的性能会稍低于迭代的方式。 但是，在实际应用中，递归方式的代码会比迭代方式的代码更加直观和易读，并且其性能损耗一般可以忽略，故通常，以递归方式编写代码会更好。除非，递归的层次太深（数千上万级别的），造成线程栈空间不足时（线程的栈空间一般为固定大小，且多为几KB），这时，应该采用迭代（循环）方案去做代码实现。 参考 Fibonacci Numbers Generator：计算斐波那契数列的站点，最大可计算数列第10000项的数值（有2090位数字） The Fibonacci series：列出了从0到300的斐波那契数列，可参照该数列检查以上代码计算结果的准确性 C Programming/stdint.h：C语言的整形类型及所表示的数值范围 How to print a int64_t type in C：如何通过printf打印uint64_t类型的值 - printf(&quot;a=%jd\\n&quot;, a); 【算法02】3种方法求解斐波那契数列：可以了解和掌握矩阵乘法求解斐波那契数列 LaTeX Math Symbols 附录以下为完整的各方案代码，并包含性能测试： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;stdint.h&gt;#include &lt;sys/time.h&gt;// uint64_t所能表示的最大整数为18446744073709551615,// 而数列的第94项将大于该数，故，这里限定最大只能求解第93项的数值，// 不过，由于数组索引为0的位置表示的为数列的第0项，故，数组的实际长度应为n+1，// 而索引位置为n的元素即为数列的第n项数值#define MAX_FIBONACCI_SIZE 94double current_timestamp();uint64_t fibonacci_recursion(uint32_t n);uint64_t fibonacci_dynamic_programming(uint32_t n);uint64_t fibonacci_loop(uint32_t n);int main(int argc, char *argv[]) &#123; uint32_t n = 0; uint64_t fib = 0; double start_time, end_time; //printf(\"Max uint64_t: %ju\\n\", UINT64_MAX); printf(\"请输入斐波那契数列长度: \"); scanf(\"%d\", &amp;n); if (n &gt;= MAX_FIBONACCI_SIZE) &#123; printf(\"得到所求数列长度为%d, 但本系统支持的最大长度为%d\\n\", n, MAX_FIBONACCI_SIZE - 1); return 1; &#125; printf(\"斐波那契数列的第%d个数为:\\n\", n); if (n &gt; 40) &#123; printf(\"- 递归算法 : 无解（求值过于耗时！）\\n\"); &#125; else &#123; start_time = current_timestamp(); fib = fibonacci_recursion(n); end_time = current_timestamp(); printf(\"- 递归算法 : %ju, 耗时: %f毫秒\\n\", fib, end_time - start_time); &#125; // Note：需要通过格式控制符 %ju 来打印uint64_t类型的数据， // 否则，会出现因精度丢失而造成输出不准确的问题 start_time = current_timestamp(); fib = fibonacci_dynamic_programming(n); end_time = current_timestamp(); printf(\"- 动态规划算法: %ju, 耗时: %f毫秒\\n\", fib, end_time - start_time); start_time = current_timestamp(); fib = fibonacci_loop(n); end_time = current_timestamp(); printf(\"- 迭代算法 : %ju, 耗时: %f毫秒\\n\", fib, end_time - start_time); return 0;&#125;// 递归法求解uint64_t fibonacci_recursion(uint32_t n) &#123; if (n == 0) &#123; return 0; &#125; else if (n == 1) &#123; return 1; &#125; return fibonacci_recursion(n - 1) + fibonacci_recursion(n - 2);&#125;// 动态规划法（Dynamic programming）求解uint64_t fibonacci_dynamic_programming(uint32_t n) &#123; static uint64_t fibonacci[MAX_FIBONACCI_SIZE] = &#123;0, 1&#125;; if (n == 0) &#123; return 0; &#125; // 数列的第n项不为0时，便可认定为已经计算过该项的值，直接返回，无需继续计算 else if (fibonacci[n] != 0) &#123; return fibonacci[n]; &#125; // 按照数列的数据公式递归求解第n项的值，并将其记录在数组中，这样，在左递归完成后，便不会再继续右递归了 else &#123; fibonacci[n] = fibonacci_dynamic_programming(n - 1) + fibonacci_dynamic_programming(n - 2); return fibonacci[n]; &#125;&#125;// 迭代法求解uint64_t fibonacci_loop(uint32_t n) &#123; if (n == 0) &#123; return 0; &#125; else if (n == 1) &#123; return 1; &#125; else &#123; // 数列的第n项 uint64_t fib_n = 0; // 数列的第n-1项，初始为第1项，值为1 uint64_t fib_n_1 = 1; // 数列的第n-2项，初始为第0项，值为0 uint64_t fib_n_2 = 0; // 开始状态： // [...................n_2....n_1...n.....] // | | | // [0, 1, 1, 2, 3, 5, n - 2, n - 1, n, ...] // 向右平移后： // [.........................n_2...n_1..n.] // | | // [0, 1, 1, 2, 3, 5, n - 2, n - 1, n, ...] for (uint32_t i = 2; i &lt;= n; i++) &#123; // 数列的第n项 = 数列的第n-1项 + 数列的第n-2项 fib_n = fib_n_1 + fib_n_2; // 向右平移1项，即， // 上一次计算的第n-1项作为下一次计算的第n-2项， // 上一次计算的第n项作为下一次计算的第n-1项 fib_n_2 = fib_n_1; fib_n_1 = fib_n; &#125; return fib_n; &#125;&#125;// 获取当前系统时间的毫秒值double current_timestamp() &#123; struct timeval te; gettimeofday(&amp;te, NULL); double msec = te.tv_sec * 1000.0 + (te.tv_usec / 1000.0); return msec;&#125;"},{"title":"算法分析：分治法求解给定集合中的众数及其重数","permalink":"https://flytreeleft.github.io/algorithm-using-divide-and-conquer-method-to-find-the-mode-in-a-set/","text":"算法分析系列文章中的代码可被任何人无偿使用于任何场景且无需注明来源也不必在使用前征得本文作者同意。 算法分析系列文章旨在传播准确、完整、简洁、易懂、规范的代码实现，并传授基本的编程思想和良好的编码习惯与技巧。 若文章中的代码存在问题或逻辑错误，请通过邮件等形式（见文章结尾）告知于本文作者以便及时修正错误或改进代码。 算法系列文章不可避免地会参考和学习众多网友的成果，在行文风格、内容及求解思路上也会进行借鉴，如有侵权嫌疑，请联系本文作者。 PS：若为转载该文章，请务必注明来源，本站点欢迎大家转载。 问题描述给定含有n个元素的多重集合S，每个元素在S中出现的次数称为该元素的重数。多重集S中重数最大的元素称为众数（mode）。 例如，S={1，2，2，2，3，5}，则，多重集S的众数是2，其重数为3。 注：众数可能存在多个。 本案例要求采用分治法求解给定集合中的众数及其重数，存在多个众数时选择第一个即可。 分治法，即，把一个复杂的问题分成两个或更多的相同或相似的子问题，直到最后子问题可以简单的直接求解，原问题的解即子问题的解的合并。（引用自「维基百科」） 求解思路分治法求解的基本思路就是将集合分成几个小部分，依次查找每个部分中的众数，再从每个部分中取出重数最大的数，该数即为所求解的众数。 在分治求解过程中，当枢轴元素（pivot）所在位置的左右两侧剩余的数据量均小于pivot的重数时，则求解结束且所求的众数即为pivot的值。 实现代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697#include&lt;stdio.h&gt;#include&lt;stdlib.h&gt;int g_mode; // 众数值int g_cnt = 0; // 众数的重数值// 优先声明相关函数定义以便于按照阅读先后顺序排列函数实现void divide_find_mode(int data[], int start_index, int end_index);int sort_and_find_pivot(int data[], int start_index, int end_index);void swap_element(int data[], int index_0, int index_1);int main(void) &#123; //int data[] = &#123;'a', 'a', 'b', 'b', 'b', '1', '2', '1'&#125;; int data[] = &#123;2, 4, 7, 8, 5, 6, 5, 5, 6, 7, 1&#125;; //int data[] = &#123;10&#125;; //int data[] = &#123;1, 2, 3&#125;; //int data[] = &#123;1, 2, 2, 2, 3, 3, 5, 6, 6, 6, 6&#125;; //int data[] = &#123;1, 2, 7, 7, 3, 5&#125;; //int data[] = &#123;3, 6, 7, 6, 4, 5&#125;; int len = sizeof(data) / sizeof(data[0]); divide_find_mode(data, 0, len - 1); printf(\"众数为: %d, 且其重数为: %d\\n\", g_mode, g_cnt); // 当集合元素为char类型时，使用以下方式输出结果 //printf(\"众数为: %c, 且其重数为: %d\\n\", g_mode, g_cnt); return 0;&#125;// 采用分治法查找集合data在指定范围（[start_index, end_index]区间）内的众数及其重数void divide_find_mode(int data[], int start_index, int end_index) &#123; int pivot_index = sort_and_find_pivot(data, start_index, end_index); // 从右边开始统计与pivot相等的元素个数（包括pivot本身） int pivot_cnt = 0; for (int i = start_index; i &lt;= pivot_index; i++) &#123; if (data[i] == data[pivot_index]) &#123; pivot_cnt++; &#125; &#125; // 记录重数最大的元素及其重数值 if (pivot_cnt &gt; g_cnt) &#123; g_mode = data[pivot_index]; g_cnt = pivot_cnt; &#125; // 若左边剩余元素数量大于当前的重数值，则继续寻找左边剩余元素（范围为[start_index, pivot_index - 1]）中的众数 // 左边剩余元素数量 = 当前众数位置左移一位（pivot_index - 1） - 查询的开始位置序号 + 1 // 如，数组&#123;1, 2, 3, 4， 5&#125;中3（其序号为2）左边剩余元素数量为2（即，2 - 1 - 0 + 1） if ((pivot_index - 1) - start_index + 1 &gt; pivot_cnt) &#123; divide_find_mode(data, start_index, pivot_index - 1); &#125; // 若右边剩余元素数量大于当前的重数值，则继续寻找右边剩余元素（范围为[pivot_index + 1, end_index]）中的众数 // 右边剩余元素数量 = 查询的结束位置序号 - 当前众数位置右移一位（pivot_index + 1） + 1 // 如，数组&#123;1, 2, 3, 4， 5&#125;中3（其序号为2）右边剩余元素数量为2（即，4 - (2 + 1) + 1） if (end_index - (pivot_index + 1) + 1 &gt; pivot_cnt) &#123; divide_find_mode(data, pivot_index + 1, end_index); &#125;&#125;// 在集合data的指定范围（[start_index, end_index]区间）内选择一个枢轴元素（pivot）并进行排序，// 以确保在该范围内pivot左边的元素均小于或等于pivot，而右边的则均大于pivotint sort_and_find_pivot(int data[], int start_index, int end_index) &#123; // 取开始位置的元素作为枢轴元素 int pivot = data[start_index]; int left_index = start_index; int right_index = end_index; // 从两边向中间推进以调整元素位置，最终确保左边的元素小于或等于pivot，而右边的元素大于pivot while (left_index &lt; right_index) &#123; // 从右边向中间推进直到遇到小于或等于pivot的元素 while (left_index &lt; right_index &amp;&amp; data[right_index] &gt; pivot) &#123; right_index--; &#125; // 从左边向中间推进直到遇到大于pivot的元素 while (left_index &lt; right_index &amp;&amp; data[left_index] &lt;= pivot) &#123; left_index++; &#125; // 将 左边大于pivot的元素 与 右边小于或等于pivot的元素 交换位置 swap_element(data, left_index, right_index); &#125; // Note：在排序过程中start_index位置的元素是不会变动位置的（其必然等于pivot）， // 而left_index位置的元素为最后一个小于或等于pivot的元素， // 这时交换二者位置后，便可确保pivot左边的元素均小于或等于pivot了 swap_element(data, start_index, left_index); return left_index;&#125;// 交换集合data中两个指定元素位置（index_0与index_1）的数据void swap_element(int data[], int index_0, int index_1) &#123; int temp = data[index_0]; data[index_0] = data[index_1]; data[index_1] = temp;&#125; 以上代码应该能够很容易看懂。这里主要强调以下几点： 对外传播的代码应该尽量降低阅读者的理解难度以及时间成本 变量名、函数名一定要能够清晰、准确地传达出其所代表的东西以及其职能，不要简单使用i、j等无意义的名称，更不要使用语义不清甚至是错误的单词 函数实现代码一般按照调用先后顺序和重要性进行排列以便于阅读并突出关键实现等 注释主要用于阐明流程、算法机制和原理、特殊代码技巧以及在调整或改进时需特别注意的事项等内容，切记不要对代码本身进行说明，说明也不要又臭又长。PS：本文为了能让刚入门的开发者看懂并阐述算法机制和过程，所以，注释写得比较详细，在实际开发中可以默认视为阅读者具备相关的算法基础，从而无需再对算法进行注释说明 一般通过sizeof(data) / sizeof(data[0])方式动态计算数组长度 实现改进上面的代码在调用sort_and_find_pivot()后存在一次遍历以获得pivot的重数（pivot_cnt），但实际上在sort_and_find_pivot()排序过程中已经存在等值比较，在这个时候是可以顺便得到pivot的重数的，只是限于C语言的函数只能返回一个值的约束而无法同时返回其重数。不过，C语言提供结构体类型，故而，可以通过在sort_and_find_pivot()后返回结构体的方式以避免不必要的遍历。 以下为改进后的代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115#include&lt;stdio.h&gt;#include&lt;stdlib.h&gt;typedef struct _Mode &#123; int value; // 众数值 int count; // 众数重复次数，即重数 int index; // 主要用于在查找pivot时记录其最终位置&#125; Mode;// 优先声明相关函数定义以便于按照阅读先后顺序排列函数实现Mode divide_find_mode(int data[], int start_index, int end_index);Mode sort_and_find_pivot(int data[], int start_index, int end_index);void swap_element(int data[], int index_0, int index_1);int compare_mode(Mode mode_0, Mode mode_1);int main(void) &#123; //int data[] = &#123;'a', 'a', 'b', 'b', 'b', '1', '2', '1'&#125;; int data[] = &#123;2, 4, 7, 8, 5, 6, 5, 5, 6, 7, 1&#125;; //int data[] = &#123;10&#125;; //int data[] = &#123;1, 2, 3&#125;; //int data[] = &#123;1, 2, 2, 2, 3, 3, 5, 6, 6, 6, 6&#125;; //int data[] = &#123;1, 2, 7, 7, 3, 5&#125;; //int data[] = &#123;3, 6, 7, 6, 4, 5&#125;; int len = sizeof(data) / sizeof(data[0]); Mode mode = divide_find_mode(data, 0, len - 1); printf(\"众数为: %d, 且其重数为: %d\\n\", mode.value, mode.count); // 当集合元素为char类型时，使用以下方式输出结果 //printf(\"众数为: %c, 且其重数为: %d\\n\", mode.value, mode.count); return 0;&#125;// 采用分治法查找集合data在指定范围（[start_index, end_index]区间）内的众数及其重数Mode divide_find_mode(int data[], int start_index, int end_index) &#123; Mode pivot = sort_and_find_pivot(data, start_index, end_index); Mode mode = pivot; // 若左边剩余元素数量大于当前的重数值，则继续寻找左边剩余元素（范围为[start_index, pivot.index - 1]）中的众数 // 左边剩余元素数量 = 当前众数位置左移一位（pivot.index - 1） - 查询的开始位置序号 + 1 // 如，数组&#123;1, 2, 3, 4， 5&#125;中3（其序号为2）左边剩余元素数量为2（即，2 - 1 - 0 + 1） if ((pivot.index - 1) - start_index + 1 &gt; pivot.count) &#123; Mode m = divide_find_mode(data, start_index, pivot.index - 1); mode = compare_mode(m, mode) &gt; 0 ? m : mode; &#125; // 若右边剩余元素数量大于当前的重数值，则继续寻找右边剩余元素（范围为[pivot.index + 1, end_index]）中的众数 // 右边剩余元素数量 = 查询的结束位置序号 - 当前众数位置右移一位（pivot.index + 1） + 1 // 如，数组&#123;1, 2, 3, 4， 5&#125;中3（其序号为2）右边剩余元素数量为2（即，4 - (2 + 1) + 1） if (end_index - (pivot.index + 1) + 1 &gt; pivot.count) &#123; Mode m = divide_find_mode(data, pivot.index + 1, end_index); mode = compare_mode(m, mode) &gt; 0 ? m : mode; &#125; return mode;&#125;// 在集合data的指定范围（[start_index, end_index]区间）内选择一个枢轴元素（pivot）并进行排序，// 以确保在该范围内pivot左边的元素均小于或等于pivot，而右边的则均大于pivotMode sort_and_find_pivot(int data[], int start_index, int end_index) &#123; int left_index = start_index; int right_index = end_index; Mode pivot = &#123; // 取开始位置的元素作为枢轴元素 .value = data[start_index], // 当只有一个元素时，则不会进行排序，也就不会有等值判断，故，count将始终为1 .count = left_index == right_index ? 1 : 0 &#125;; // 从两边向中间推进以调整元素位置，最终确保左边的元素小于或等于pivot，而右边的元素大于pivot while (left_index &lt; right_index) &#123; // 从右边向中间推进直到遇到小于或等于pivot的元素 while (left_index &lt; right_index &amp;&amp; data[right_index] &gt; pivot.value) &#123; right_index--; &#125; if (left_index &lt; right_index &amp;&amp; data[right_index] == pivot.value) &#123; pivot.count++; &#125; // 从左边向中间推进直到遇到大于pivot的元素 while (left_index &lt; right_index &amp;&amp; data[left_index] &lt;= pivot.value) &#123; if (data[left_index] == pivot.value) &#123; pivot.count++; &#125; left_index++; &#125; // 将 左边大于pivot的元素 与 右边小于或等于pivot的元素 交换位置 swap_element(data, left_index, right_index); &#125; // Note：在排序过程中start_index位置的元素是不会变动位置的（其必然等于pivot）， // 而left_index位置的元素为最后一个小于或等于pivot的元素， // 这时交换二者位置后，便可确保pivot左边的元素均小于或等于pivot了 swap_element(data, start_index, left_index); pivot.index = left_index; return pivot;&#125;// 交换集合data中两个指定元素位置（index_0与index_1）的数据void swap_element(int data[], int index_0, int index_1) &#123; if (index_0 == index_1) &#123; return; &#125; int temp = data[index_0]; data[index_0] = data[index_1]; data[index_1] = temp;&#125;int compare_mode(Mode mode_0, Mode mode_1) &#123; return mode_0.count - mode_1.count;&#125; 这里主要强调以下几点： 在离调用最近的位置处声明变量，避免变量声明位置与第一次使用位置相隔太远 结构体数据的初始化采用(ANSI) C99方式以便于阅读，如，struct point p = { .y = yvalue, .x = xvalue };"},{"title":"记一次惊心动魄的CentOS系统升级经历","permalink":"https://flytreeleft.github.io/a-horrible-os-upgrading-for-centos/","text":"How to use yum history to roll back an update12345# List all update historiesyum history# Undo the specified transactionyum history undo &lt;transaction ID&gt; Fix ‘has missing requires of’12345678cp -a /var/lib/rpm /var/lib/rpm.bakcp -a /var/lib/yum /var/lib/yum.bakyum check \\ | grep \"has missing requires of\" \\ | awk '&#123;print $1&#125;' \\ | sed -E \"s/^[0-9]+://g\" \\ | while read p; do rpm -e --nodeps $p; done Fix ‘is a duplicate with’12345678910111213cp -a /var/lib/rpm /var/lib/rpm.bakcp -a /var/lib/yum /var/lib/yum.bakyum check \\ | grep \"is a duplicate with\" \\ | awk '&#123;print $1&#125;' \\ | sed -E \"s/^[0-9]+://g\" \\ | while read p; do rpm -e --justdb --nodeps $p; doneyum update# If 'yum update' still get some duplicated packages, just running the following commands## yum update | grep \"is a duplicate with\" | awk '&#123;print $1&#125;' | sed -E \"s/^[0-9]+://g\" | while read p; do rpm -e --justdb --nodeps $p; done## yum update"},{"title":"Nginx特例场景配置","permalink":"https://flytreeleft.github.io/the-special-case-configuration-of-nginx/","text":"本文所使用的相关代码片段可从 https://github.com/flytreeleft/docker-nginx-gateway 得到完整内容。 Nginx随机展示自定义错误页面 Source code: https://github.com/flytreeleft/docker-nginx-gateway/tree/master/config/error-pagesCustom error pages: https://github.com/flytreeleft/docker-nginx-gateway/tree/master/examples/epage.d/all 关键字： 随机展示多个错误页面 Nginx自定义错误页面 在访问HTTP站点时最容易出现的错误就是404，于是就有许多非常有个性的404错误页面。而为我们自己的站点放置一些简洁、清爽的错误页面，在资源再利用的前提下，也将为我们自身增加不少好感和亲和力。 这里将要介绍的便是如何为我们的站点配置自定义错误页面，并同时支持为相同错误随机展示不同的错误页面。 分类展示分类展示就是相同类型的错误使用同种风格的错误页面，这里简单分为404、40x（主要为400，401，403）、50x（主要为500，502，503，504），其配置内容如下： 1234567891011121314151617181920212223242526272829303132333435363738# Obmit the `[=[response]]` syntax to keep the error response code for clients.## http://nginx.org/en/docs/http/ngx_http_core_module.html#error_pageerror_page 404 /404/;error_page 400 401 403 /40x/;error_page 500 502 503 504 /50x/;location /404/ &#123; internal; random_index on; root /etc/nginx/epage.d;&#125;location /40x/ &#123; internal; random_index on; root /etc/nginx/epage.d; # Replace the placeholders in response content # for showing the corresponding status and message. sub_filter '&#123;&#123;status&#125;&#125;' '$status'; sub_filter '&#123;&#123;status_msg&#125;&#125;' '$status_msg'; sub_filter_once off;&#125;location /50x/ &#123; internal; random_index on; root /etc/nginx/epage.d; # Replace the placeholders in response content # for showing the corresponding status and message. sub_filter '&#123;&#123;status&#125;&#125;' '$status'; sub_filter '&#123;&#123;status_msg&#125;&#125;' '$status_msg'; sub_filter_once off;&#125; 这里将错误页面分别放置于/etc/nginx/epage.d/404/、/etc/nginx/epage.d/40x/、/etc/nginx/epage.d/50x/三个目录中，通过random_index指令可随机从这些目录中选择后缀为html的文件并返回给客户端，也就达到了错误页面随机展示的效果。注：1. internal指令限制了只能在Nginx内部请求该地址，外部访问将返回404错误；2. 若不需要随机展示的特性，在目录中始终放置一个HTML文件即可。 指令sub_filter用于过滤响应体中的特定字符串并替换为目标字符串。这里主要是替换{{status}}和{{status_msg}}（此为精确匹配，不能含其他字符）两个占位符以显示具体的错误码和错误信息，在错误页面中的合适位置引入这两个占位符即可。另外，$status_msg为与变量$status对应的状态信息，完整的映射关系见tmthrgd/nginx-status-text.conf。注：sub_filter_once off;为启用多次替换，确保页面中所有的占位符均被替换。 在引入该配置时需注意，该配置内容需添加到每个站点（即server {}）配置中，暂时不知道如何进行全局配置。为了方便可将以上内容放到单独的文件中（如，epage.conf）再通过include指令引入该配置。 统一展示统一展示就是所有错误都由相同页面展示，不同的只是显示的错误码和错误信息。以下为该方式的配置内容： 123456789101112131415161718# Obmit the `[=[response]]` syntax to keep the error response code for clients.## http://nginx.org/en/docs/http/ngx_http_core_module.html#error_pageerror_page 404 400 401 403 500 502 503 504 /_/;location /_/ &#123; internal; random_index on; # http://nginx.org/en/docs/http/ngx_http_core_module.html#alias # https://stackoverflow.com/questions/10631933/nginx-static-file-serving-confusion-with-root-alias#answer-10647080 alias /etc/nginx/epage.d/all/; # Replace the placeholders in response content # for showing the corresponding status and message. sub_filter '&#123;&#123;status&#125;&#125;' '$status'; sub_filter '&#123;&#123;status_msg&#125;&#125;' '$status_msg'; sub_filter_once off;&#125; 这里的配置内容和注意事项与分类展示的基本相同，所不同的是，错误页面被放置在/etc/nginx/epage.d/all/目录中，与分类展示的目录独立，从而可按需自由转换展示模式。 Nginx代理第三方http站点静态资源文件关键字： HTTPS反向代理HTTP静态资源 单页面Markdown编写与渲染方案 Nginx反向代理重定向拦截处理 这几天为部门搭建好了Maven仓库，为了便于指导部门同事能够准确配置并启用私有仓库，然后就打算写一份使用说明文档。 我不太喜欢写Word，也好几年几乎没用过了，一般都是直接写在部门的Wiki系统上。不过，一份简单的文档写到Wiki上又不太方便查阅，于是找了找可以在单个HTML里写Markdown并直接渲染展示的方案。 很快我就找到了Strapdown Zeta，其对Mardown的支持较为全面，并且使用很简单，还提供多套主题可自由切换。需要提到的是该库为Strapdown的衍生与改进版本，而Strapdown已经很长时间未更新了，选择Strapdown Zeta也是看重其活跃度。 在Strapdown Zeta的支持下仅需在&lt;xmp&gt;&lt;/xmp&gt;标签中编写Markdown并在最后引入 http://cdn.ztx.io/strapdown/strapdown.min.js 脚本即可。可惜的是，作者提供的该站点并未启用HTTPS，而我们在Let’s Encrypt的帮助下已经对部门的所有站点启用了HTTPS。这样，若在页面中引用非HTTPS资源，浏览器默认将阻止该资源的下载。 显然，这里不能直接在页面中引入该脚本，但是我也不愿再在站点上部署除使用文档之外的其他文件，就仅仅一个HTML文件即可，css什么的都不要有。 百般思索后，突然想到Internet Archive可以代理访问其他站点的页面，那我也可以专门为第三方静态资源搭建一个代理服务，该站点自身是HTTPS的，其在服务端获取到目标资源再返回给浏览器，这样该资源也就走的是HTTPS，既不用在服务器上存储这些资源，也可以自由代理其他第三方资源，而且不用管目标是不是HTTPS，甚至还可以代理一些无法访问到的资源。简单、经济、又实惠！:) 于是动手！这里假设代理站点为https://static.example.com，并构造代理链接为https://static.example.com/*/&lt;target url&gt;形式，这种结构可以方便Nginx做Location匹配，同时在使用和修改上均十分简单，我们不用改变目标资源的URL地址。 这里直接放出完整的配置：123456789101112131415161718192021222324252627282930313233343536373839server &#123; listen 443 ssl; listen [::]:443 ssl; server_name static.example.com; include /etc/nginx/vhost.d/static.example.com/01_ssl.conf; # https://static.example.com/*/http://others.com/asset.js -&gt; http://others.com/asset.js ## https://www.mediasuite.co.nz/blog/proxying-s3-downloads-nginx/ location ~* ^/\\*/(http[s]?):?/(.*?)/(.*)$ &#123; # Note: Remove the directive 'internal;' to accept the external requests, # otherwise it will return 404 for the external requests. # See http://nginx.org/en/docs/http/ngx_http_core_module.html#internal set $backend_protocol $1; set $backend_host $2; set $backend_path $3; set $backend_uri $backend_host/$backend_path$is_args$args; set $backend_url $backend_protocol://$backend_uri; # Headers for the remote server, unset Authorization and Cookie for security reasons. proxy_set_header Host $backend_host; proxy_set_header Authorization ''; proxy_set_header Cookie ''; # Stops the local disk from being written to (just forwards data through) proxy_max_temp_file_size 0; proxy_pass $backend_url; proxy_intercept_errors on; error_page 301 302 307 = @handle_backend_redirect; &#125; # Nginx Embedded Variables: http://nginx.org/en/docs/varindex.html location @handle_backend_redirect &#123; return 302 $scheme://$host/*/$upstream_http_location; &#125;&#125; 该配置参考的是Using NGINX’s X-Accel with Remote URLs。这里没有做特别的改动，主要是针对我们的实际需求做了些调整： 去掉了internal;指令，该指令是限制仅能在Nginx内部做该代理请求，而我们是需要外部直接获取到目标资源的，因此，需要去掉该指令，否则，外部访问时将始终为404； 针对目标URL地址存在重定向问题，在@handle_backend_redirect中，我又将重定向地址（其对应变量$upstream_http_location）再次进行代理，这样无论目标跳转多少次，代理站点均能获取到最终的返回内容，而不是在浏览器中又突然跳到另一个HTTP链接了； 最后提醒大家一点是，在网络中对安全要时刻保持警惕，尽可能降低敏感数据泄漏的风险，因此，这里切忌不要将客户端的Authorization和Cookie转发到目标站点了。 Nginx通过Squid穿透防火墙 Source code: https://github.com/flytreeleft/docker-nginx-gateway/blob/master/examples/vhost.d/static.example.com.conf 关键字： Nginx http_proxy：http_proxy为Linux中配置启用正向代理的环境变量，很多命令可识别该变量并通过所设定的代理地址请求目标资源 Nginx防火墙穿透 Nginx over Squid Squid behind Nginx Nginx bypass firewall via Squid 在前面提到，为了将HTTP请求转换为HTTPS请求，我专门搭建了个静态文件代理站点。刚开始访问还很正常，可后来便发现公司网关阻止了服务器对外部网站的访问，导致编写的文档无法渲染。 因此，我便考虑在Nginx服务端通过Squid（其他代理服务也可）再做一次代理以穿透公司的防火墙，确保静态资源的代理不再出现问题。 在多次尝试以及搜索网络资料后终于发现How to make an existing caching Nginx proxy use another proxy to bypass a firewall?所提到的实现方法。 在原配置的基础上综合改进后，得到新的配置内容如下：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455server &#123; listen 443 ssl; listen [::]:443 ssl; server_name static.example.com; include /etc/nginx/vhost.d/static.example.com/01_ssl.conf; # https://static.example.com/*/http://others.com/asset.js -&gt; http://others.com/asset.js ## https://www.mediasuite.co.nz/blog/proxying-s3-downloads-nginx/ location ~* ^/\\*/(http[s]?):?/(.*?)/(.*)$ &#123; # Note: Remove the directive 'internal;' to accept the external requests, # otherwise it will return 404 for the external requests. # See http://nginx.org/en/docs/http/ngx_http_core_module.html#internal set $backend_protocol $1; set $backend_host $2; set $backend_path $3; set $backend_uri $backend_host/$backend_path$is_args$args; set $backend_url $backend_protocol://$backend_uri; # Headers for the remote server, unset Authorization and Cookie for security reasons. proxy_set_header Host $backend_host; proxy_set_header Authorization ''; proxy_set_header Cookie ''; # Stops the local disk from being written to (just forwards data through) proxy_max_temp_file_size 0; # Forward the target to the squid proxy ## https://serverfault.com/questions/583743/how-to-make-an-existing-caching-nginx-proxy-use-another-proxy-to-bypass-a-firewa#683955 ## Hide the reponse header to protect the backend proxy ### http://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_hide_header proxy_hide_header Via; proxy_hide_header X-Cache; proxy_hide_header X-Cache-Hits; proxy_hide_header X-Cache-Lookup; proxy_hide_header X-Fastly-Request-ID; proxy_hide_header X-Served-By; proxy_hide_header X-Timer; rewrite ^(.*)$ \"://$backend_uri\" break; rewrite ^(.*)$ \"$backend_protocol$1\" break; proxy_pass http://&lt;squid ip&gt;:3128; # Proxy to the target directly #proxy_pass $backend_url; proxy_intercept_errors on; error_page 301 302 307 = @handle_backend_redirect; &#125; # Nginx Embedded Variables: http://nginx.org/en/docs/varindex.html location @handle_backend_redirect &#123; return 302 $scheme://$host/*/$upstream_http_location; &#125;&#125; 这里需要特别注意的是： 这里做了两次rewrite是为了确保能够准确将目标URL地址附加到Squid的代理地址中以构成http://&lt;squid ip&gt;:3128/&lt;target url&gt;形式，同时，规避了因在rewrite的替换字符串中包含http://、https://或$scheme而导致重定向的问题； 同样为了安全考虑，这里隐藏了Squid的几个响应头，避免客户端得到Squid的真实IP地址而产生潜在的攻击风险； Nginx反向代理Nexus3的不同类型仓库关键字： Nginx反向代理 Nexus3不同类型仓库映射独立域名 Nexus3同时支持多种类型的资源存储，比如，Docker镜像、Maven依赖包、NPM等，不过，不同类型的资源访问方式和使用惯例是不一致的，因此，为每类资源提供符合惯例的仓库地址，再将请求转发到Nexus3仓库，对使用者而言将更加有好。 为此，本例针对Docker、Maven和NPM仓库分别给出Nginx的反向代理配置。 首先确定几个子站点的域名为如下形式： https://repo.example.com：Nexus3服务访问地址 https://mvn.example.com：Maven仓库访问地址 https://npm.example.com：NPM仓库地址 https://dcr.example.com：Docker镜像访问地址 https://repo.example.com的反向代理配置 Source code: https://github.com/flytreeleft/docker-nginx-gateway/blob/master/examples/vhost.d/repo.example.com.conf#L15 123456789101112131415server &#123; listen 443 ssl; listen [::]:443 ssl; server_name repo.example.com; include /etc/nginx/vhost.d/repo.example.com/01_ssl.conf; proxy_cache off; location / &#123; # Avoid to get address resolve error when starting set $nexus3 http://&lt;nexus3 ip&gt;:&lt;nexus3 web port&gt;; proxy_pass $nexus3; &#125;&#125; 对https://repo.example.com的配置很简单，直接将请求反向代理到Nexus3的Web接口即可。这里仅需要注意以下几点： 为了避免Nginx缓存导致资源的元数据（metadata）不能及时更新，所以，这里启用了proxy_cache off;以关闭代理缓存。当然，也可以根据实际情况仅对某些类的文件关闭缓存 Nginx在解析配置时会对proxy_pass的目标域名地址进行解析，若是解析失败则会导致Nginx启动异常，因此，这里采用变量方式将解析延迟到需要时，从而避免启动失败 https://mvn.example.com的反向代理配置 Source code: https://github.com/flytreeleft/docker-nginx-gateway/blob/master/examples/vhost.d/repo.example.com.conf#L110 需要科普一下的是，在Nexus3中访问某个仓库内的资源的URL结构为http://&lt;nexus3&gt;/#browse/browse/components:&lt;repo&gt;/，访问某个资源的URL结构为http://&lt;nexus3&gt;/repository/&lt;repo&gt;/&lt;asset path&gt;。其中，&lt;repo&gt;为仓库名称，所有类型的仓库均会有hosted（私有存储）、proxy（代理外部仓库）和group（组合同类仓库）三种模式。 为了规范内部和外部访问并便于进行权限控制（如，外部帐号不允许访问hosted中的源码等），这里创建了以下几个仓库： maven-hosted-releases：存储内部产品发布包。部署发布包时，向该仓库发送更新请求 maven-hosted-snapshots：存储内部产品开发快照包。部署快照包时，向该仓库发送更新请求 maven-hosted：maven-hosted-*的组合仓库。在Maven客户端更新依赖时，从该仓库下载内部产品的发布包或快照包 maven-&lt;3rd repo url&gt;：对第三方仓库的代理仓库，&lt;3rd repo url&gt;为站点域名，比如，maven-apache.org。也可以按其他规范命名，只要能友好区分不同仓库即可 maven-public：所有maven-&lt;3rd repo url&gt;的组合仓库。用于统一下载第三方的依赖包 然后，我们期望在访问以下URL链接时，能够将请求转发到对应的资源上： GET https://mvn.example.com/public/&lt;asset&gt; -&gt; https://repo.example.com/repository/maven-public/&lt;asset&gt; GET https://mvn.example.com/hosted/&lt;asset&gt; -&gt; https://repo.example.com/repository/maven-hosted/&lt;asset&gt; GET https://mvn.example.com/releases/&lt;asset&gt; -&gt; https://repo.example.com/repository/maven-hosted/&lt;asset&gt; GET https://mvn.example.com/snapshots/&lt;asset&gt; -&gt; https://repo.example.com/repository/maven-hosted/&lt;asset&gt; POST https://mvn.example.com/releases/&lt;asset&gt; -&gt; https://repo.example.com/repository/maven-hosted-releases/&lt;asset&gt; POST https://mvn.example.com/snapshots/&lt;asset&gt; -&gt; https://repo.example.com/repository/maven-hosted-snapshots/&lt;asset&gt; 根据以上规范和需求，https://mvn.example.com的最终配置如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445server &#123; listen 443 ssl; listen [::]:443 ssl; server_name mvn.example.com; include /etc/nginx/vhost.d/mvn.example.com/01_ssl.conf; # Redirect to the maven repository (named as 'maven-public') of Nexus3 location = / &#123; return 302 $scheme://repo.example.com/#browse/browse/components:maven-public/; &#125; # Redirect to the target asset of Nexus3 location ~* ^/repository/maven-.+$ &#123; return 301 $scheme://repo.example.com$request_uri; &#125; # Disable cache of assets proxy_cache off; proxy_read_timeout 300; proxy_connect_timeout 300; location / &#123; set $nexus3 http://&lt;nexus3 ip&gt;:&lt;nexus3 web port&gt;; # NOTE: rewrite and proxy_pass should be put in the same block ## http://nginx.org/en/docs/http/ngx_http_rewrite_module.html#rewrite # web browse or `mvn compile` if ($request_method ~* \"^GET|HEAD$\") &#123; rewrite ^/public/(.*) /repository/maven-public/$1 break; rewrite ^/hosted/(.*) /repository/maven-hosted/$1 break; rewrite ^/releases/(.*) /repository/maven-hosted/$1 break; rewrite ^/snapshots/(.*) /repository/maven-hosted/$1 break; proxy_pass $nexus3; break; &#125; # `mvn deploy` if ($request_method ~* \"^POST|PUT$\") &#123; rewrite ^/(releases|snapshots)/(.*) /repository/maven-hosted-$1/$2 break; proxy_pass $nexus3; break; &#125; &#125;&#125; 这里需要注意以下几点： 在前两个location匹配后均跳转到https://repo.example.com，因为，这两个地址的请求可认为只能是从浏览器发出的，直接跳转到Nexus3可让访问者了解我们使用的是Nexus3系统，从而尽快熟悉该系统，完全没有必要将Nexus3代理到https://mvn.example.com域名下 return 301代表固定跳转，浏览器后续访问相同URL时将直接跳转到指定的目标，而不会再向服务器发送请求；而return 302为临时跳转，浏览器的后续访问依然会向服务器发送请求。对= /做临时跳转是因为我们可能会在该URL下放些说明文档之类的页面，如果做固定跳转，那么若后续支持该需求则只能在客户端清空浏览器Cookie后方能生效，对使用者会造成一定困扰 看过Maven代码可以发现其使用的HttpClient库向仓库发送HTTP请求，所以，只需要对$request_method做匹配，将读请求转发到maven-pulic和maven-hosted两个组合仓库中，而将写请求转发到maven-hosted-*仓库即可 剩下的就是调整Maven settings.xml。对普通的仅做依赖下载更新的配置为（仅列出主要内容，请按实际需求修改）：12345678910111213141516171819202122232425262728293031323334353637383940414243444546&lt;!-- https://maven.apache.org/settings.html --&gt;&lt;settings&gt; &lt;servers&gt; &lt;server&gt; &lt;!-- Associated with &lt;repository/&gt; and &lt;pluginRepository/&gt; --&gt; &lt;id&gt;your-repo-public&lt;/id&gt; &lt;username&gt;&lt;/username&gt; &lt;password&gt;&lt;/password&gt; &lt;/server&gt; &lt;server&gt; &lt;id&gt;your-repo-hosted&lt;/id&gt; &lt;username&gt;&lt;/username&gt; &lt;password&gt;&lt;/password&gt; &lt;/server&gt; &lt;/servers&gt; &lt;profiles&gt; &lt;profile&gt; &lt;id&gt;your-repo&lt;/id&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;your-repo-public&lt;/id&gt; &lt;url&gt;https://mvn.example.com/public/&lt;/url&gt; &lt;releases&gt;&lt;enabled&gt;true&lt;/enabled&gt;&lt;/releases&gt; &lt;snapshots&gt;&lt;enabled&gt;true&lt;/enabled&gt;&lt;/snapshots&gt; &lt;/repository&gt; &lt;repository&gt; &lt;id&gt;your-repo-hosted&lt;/id&gt; &lt;url&gt;https://mvn.example.com/hosted/&lt;/url&gt; &lt;releases&gt;&lt;enabled&gt;true&lt;/enabled&gt;&lt;/releases&gt; &lt;snapshots&gt;&lt;enabled&gt;true&lt;/enabled&gt;&lt;/snapshots&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;pluginRepositories&gt; &lt;pluginRepository&gt; &lt;id&gt;your-repo-public&lt;/id&gt; &lt;url&gt;https://mvn.example.com/public/&lt;/url&gt; &lt;releases&gt;&lt;enabled&gt;true&lt;/enabled&gt;&lt;/releases&gt; &lt;snapshots&gt;&lt;enabled&gt;true&lt;/enabled&gt;&lt;/snapshots&gt; &lt;/pluginRepository&gt; &lt;/pluginRepositories&gt; &lt;/profile&gt; &lt;/profiles&gt; &lt;activeProfiles&gt; &lt;activeProfile&gt;your-repo&lt;/activeProfile&gt; &lt;/activeProfiles&gt;&lt;/settings&gt; 而对需要向仓库部署包的配置则为（仅列出主要内容，请按实际需求修改）：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768&lt;!-- https://maven.apache.org/settings.html --&gt;&lt;settings&gt; &lt;servers&gt; &lt;server&gt; &lt;!-- Associated with &lt;repository/&gt; and &lt;pluginRepository/&gt; --&gt; &lt;id&gt;public&lt;/id&gt; &lt;username&gt;&lt;/username&gt; &lt;password&gt;&lt;/password&gt; &lt;/server&gt; &lt;server&gt; &lt;id&gt;releases&lt;/id&gt; &lt;username&gt;&lt;/username&gt; &lt;password&gt;&lt;/password&gt; &lt;/server&gt; &lt;server&gt; &lt;id&gt;snapshots&lt;/id&gt; &lt;username&gt;&lt;/username&gt; &lt;password&gt;&lt;/password&gt; &lt;/server&gt; &lt;server&gt; &lt;id&gt;thirdparty&lt;/id&gt; &lt;username&gt;&lt;/username&gt; &lt;password&gt;&lt;/password&gt; &lt;/server&gt; &lt;/servers&gt; &lt;profiles&gt; &lt;profile&gt; &lt;id&gt;your-repo&lt;/id&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;public&lt;/id&gt; &lt;url&gt;https://mvn.example.com/public/&lt;/url&gt; &lt;releases&gt;&lt;enabled&gt;true&lt;/enabled&gt;&lt;/releases&gt; &lt;snapshots&gt;&lt;enabled&gt;true&lt;/enabled&gt;&lt;/snapshots&gt; &lt;/repository&gt; &lt;repository&gt; &lt;id&gt;releases&lt;/id&gt; &lt;url&gt;https://mvn.example.com/releases/&lt;/url&gt; &lt;releases&gt;&lt;enabled&gt;true&lt;/enabled&gt;&lt;/releases&gt; &lt;snapshots&gt;&lt;enabled&gt;false&lt;/enabled&gt;&lt;/snapshots&gt; &lt;/repository&gt; &lt;repository&gt; &lt;id&gt;snapshots&lt;/id&gt; &lt;url&gt;https://mvn.example.com/snapshots/&lt;/url&gt; &lt;releases&gt;&lt;enabled&gt;false&lt;/enabled&gt;&lt;/releases&gt; &lt;snapshots&gt;&lt;enabled&gt;true&lt;/enabled&gt;&lt;/snapshots&gt; &lt;/repository&gt; &lt;repository&gt; &lt;id&gt;thirdparty&lt;/id&gt; &lt;url&gt;https://mvn.example.com/thirdparty/&lt;/url&gt; &lt;releases&gt;&lt;enabled&gt;true&lt;/enabled&gt;&lt;/releases&gt; &lt;snapshots&gt;&lt;enabled&gt;true&lt;/enabled&gt;&lt;/snapshots&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;pluginRepositories&gt; &lt;pluginRepository&gt; &lt;id&gt;public&lt;/id&gt; &lt;url&gt;https://mvn.example.com/public/&lt;/url&gt; &lt;releases&gt;&lt;enabled&gt;true&lt;/enabled&gt;&lt;/releases&gt; &lt;snapshots&gt;&lt;enabled&gt;true&lt;/enabled&gt;&lt;/snapshots&gt; &lt;/pluginRepository&gt; &lt;/pluginRepositories&gt; &lt;/profile&gt; &lt;/profiles&gt; &lt;activeProfiles&gt; &lt;activeProfile&gt;your-repo&lt;/activeProfile&gt; &lt;/activeProfiles&gt;&lt;/settings&gt; 注意，Maven在更新时是按照settings.xml中定义的仓库顺序依次查找依赖直到内置的central仓库，若在某个仓库中找到依赖则停止查找。因此，需要注意调整仓库的位置以避免因依赖同名而导致下载的内容与预期的不同。 https://npm.example.com的反向代理配置 Source code: https://github.com/flytreeleft/docker-nginx-gateway/blob/master/examples/vhost.d/repo.example.com.conf#L182 https://npm.example.com与https://mvn.example.com的规划和注意事项基本一致，只是npm-hosted仓库直接使用hosted模式，因为NPM依赖包没有快照版本，而npm-public仓库依然为group模式，用于组合多个第三方仓库。 以下为对https://npm.example.com的完整配置： 12345678910111213141516171819202122232425262728293031323334353637383940414243server &#123; listen 443 ssl; listen [::]:443 ssl; server_name npm.example.com; include /etc/nginx/vhost.d/npm.example.com/01_ssl.conf; # Redirect to the npm repository (named as 'npm-public') of Nexus3 location = / &#123; return 302 $scheme://repo.example.com/#browse/browse/components:npm-public/; &#125; # Redirect to the target asset of Nexus3 location ~* ^/repository/npm-.+$ &#123; return 301 $scheme://repo.example.com$request_uri; &#125; # Disable cache of assets proxy_cache off; proxy_read_timeout 60; proxy_connect_timeout 60; location / &#123; set $nexus3 http://&lt;nexus3 ip&gt;:&lt;nexus3 web port&gt;; # NOTE: rewrite and proxy_pass should be put in the same block ## http://nginx.org/en/docs/http/ngx_http_rewrite_module.html#rewrite # web browse or `npm install` if ($request_method ~* \"^GET$\") &#123; rewrite ^/(.+) /repository/npm-public/$1 break; proxy_pass $nexus3; break; &#125; # `npm publish` if ($request_method ~* \"^PUT|DELETE$\") &#123; rewrite ^/(.+) /repository/npm-hosted/$1 break; proxy_pass $nexus3; break; &#125; &#125;&#125; 在安装或发布模块时可通过选项--registry临时指定目标仓库地址： 安装模块：npm --registry=https://npm.example.com install &lt;module&gt; 发布模块：npm --registry=https://npm.example.com publish &lt;folder&gt; 也可以替换默认仓库，直接使用私有仓库：npm config set registry https://npm.example.com。 若需要还原为默认仓库，则运行命令npm config set registry https://registry.npmjs.org。 登录仓库则执行命令npm login --registry=https://npm.example.com。 https://dcr.example.com的反向代理配置 Source code: https://github.com/flytreeleft/docker-nginx-gateway/blob/master/examples/vhost.d/repo.example.com.conf#L50 在Nexus3中，Docker类型的仓库需要使用不同的端口进行访问，创建仓库时需要为仓库自行设定一个HTTP端口号，然后再通过Nginx将读写请求转发到不同的端口上。 这里创建一个hosted模式的仓库docker-hosted用于docker push镜像，创建一个group模式的仓库docker-public用于组合多个第三方镜像仓库。 最终，针对https://dcr.example.com的Nginx配置如下： 12345678910111213141516171819202122232425262728293031323334353637server &#123; listen 443 ssl; listen [::]:443 ssl; server_name dcr.example.com; include /etc/nginx/vhost.d/dcr.example.com/01_ssl.conf; # Disable cache of assets proxy_cache off; proxy_read_timeout 600; proxy_connect_timeout 600; location / &#123; if ($http_user_agent !~* \"^docker/.+$\") &#123; return 301 $scheme://repo.example.com/#browse/browse/components:docker-public$request_uri; &#125; set $nexus3 http://&lt;nexus3 ip&gt;; # docker pull dcr.example.com/xx-xx set $repo_url $nexus3:&lt;docker-public port&gt;; # https://github.com/moby/moby/blob/7061b0f748c29ffd1e6852cdc5dd11f90840eb1c/daemon/logger/awslogs/cloudwatchlogs_test.go#L71 # https://github.com/moby/moby/blob/master/client/image_pull.go # https://github.com/moby/moby/blob/master/client/image_push.go # NOTE: rewrite and proxy_pass should be put in the same block ## http://nginx.org/en/docs/http/ngx_http_rewrite_module.html#rewrite # docker push dcr.example.com/xx-xx if ($request_method ~* \"^HEAD|POST|PUT|DELETE|PATCH$\") &#123; set $repo_url $nexus3:&lt;docker-hosted port&gt;; &#125; proxy_pass $repo_url; &#125;&#125; 这里同样需注意以下几个问题： Docker发送的HTTP请求中User Agent包含docker字符串，因此，如果$http_user_agent中没有这个字符串，则视为浏览器访问，直接跳转到https://repo.example.com 从Docker的源码中可以发现HTTP Method为HEAD、POST、PUT、DELETE、PATCH均与镜像变更（新增、删除、打标签、更新等）有关，因此，需要将这些请求均转发到docker-hosted仓库 在使用时可分别通过以下命令登录仓库以及拉取或推送镜像： 登录仓库：docker login dcr.example.com 拉取镜像：docker pull dcr.example.com/&lt;image name&gt;:&lt;image version&gt; 推送镜像：docker push dcr.example.com/&lt;image name&gt;:&lt;image version&gt;"},{"title":"未来社会形态畅想","permalink":"https://flytreeleft.github.io/the-future-social-formation/","text":"The post isn’t finished yet, it will be updated anytime! 无现金社会提要： 比特币、比特交易网络 以太坊 IOTA 如何找回IOTA余额：可以从中了解转账机制与流程 自由工作提要： 为个人价值体现、兴趣、探索未知而工作，而不是为了生活和生存 社会基础能够保障个人衣食无忧，确保个人在任何时刻都无需担心温饱和居住问题，从而有精力专注于思考和探索上 种植、生产、制造、输送流程实现全自动化、机械化 自由选择工作时间、工作地点，不为特定的个人、团体、组织、企业工作，仅为达到某个目标而做事并获得对等回报 万物互联提要： 联网的每个设备既为内容消费端，也是内容存储端，同时也是网络热点，附近的设备可随时且自由地连接在一起 基于内容进行网络访问，而不再基于IP或域名，任何端点都可能含有所需内容，就近选择并从该端点下载内容即可，内容原始发布端将无关紧要 分布式、无中心化的基础网络，不再需要路由器、交换机、服务器等中心设备 初始阶段需要通过ISP打通各个闭环网络（闭环的连接设备群组），当多个闭环网络连接形成足够大的闭环后，设备之间的通信将无需ISP的支持 家用路由器等可自由共享网络，助推「万物网」的形成"},{"title":"作恶行为清单","permalink":"https://flytreeleft.github.io/the-evil-behaviors/","text":"列举日常和网络中所发现的软件、应用、服务等的「作恶」行为，将其永久钉在「耻辱柱」上。有条件的或有候选方案的，应主动弃用之！坚持开放、坚持自由。点击下载自由软件自由社会.pdf就事论事，不针对个人、企业、平台，挖掘现象本质，努力尝试寻找更优方案 为逼迫用户使用客户端而阉割Web端的基本功能 案例： 闲鱼Web端隐藏搜索框 来源： https://www.appinn.com/xianyu-search-box/ 评语： 若欲达KPI，必先「中二自宫」 封闭平台之间因为利益互怼，以用户为筹码逼迫对方作出让步 案例： 谷歌Youtube禁止亚马逊Echo访问 来源： http://www.ifanr.com/951314 相关： 360与QQ大战、菜鸟与顺丰互怼 评语： 用户在我手，天下跟我走。看不惯？你咬我呀！ 观点： 在「封闭平台」中，用户从一开始便是平台的筹码，当平台「自认为」利益受到其他平台威胁时，便会不惜以损害用户体验的方式进行反击，其平日讨好用户的伪善面目便暴露无疑。平台越大，心眼越小，不安全感越严重，思路越单一，解决问题的方式越是直接粗暴。"},{"title":"软件开发最佳实践","permalink":"https://flytreeleft.github.io/the-better-software-development-practice/","text":"任何局部优化都是在浪费生命 不要仅凭感觉去做性能和代码优化或者是重构代码，一定要以性能测试和监控分析结果为依据，重点优化和改进关键代码和影响常用功能的代码。 需要认识到和牢记的是，局部的小改进对业务整体而言是毫无意义的，只有从全局角度所做的改进才是可感知且有价值的。 不要原地打转：开发工作不要阻塞在单一技术点上，以完成业务功能为首要目标，不影响整体架构的技术难点可利用空闲时间解决 出现任何问题都始终保持就事论事的态度，不要带有个人情绪，不要在未查明根本原因的情况下将问题归咎于个人能力、品行或态度，应优先考虑提升项目管理、工作分配、人员激励、运维管理等制度和服务 快速出错，快速修复：Let it Crash（https://www.zhihu.com/question/22295393/answer/20912297） 如果不知道或不确定如何处理异常，那就让它抛出，甚至是让程序崩溃，从而让问题尽早出现并提前修复掉。 将异常“吃掉”是不负责任的，至少也应该打印到异常日志中（日志级别为ERROR），这样才有利于及时定位根源。 为避免单例程序崩溃导致服务不可用，可同时部署多个实例，提供冗余服务机制，这样就可以不用想各种方法来避免程序崩溃了，有了服务冗余，就让它崩溃吧。PS：确保崩溃的服务能够快速重启也是很重要的。 无论是开发最终应用，还是基础框架，切忌，不要向使用者（普通用户或开发人员）暴露底层细节，更不要向使用者强制灌输细节内容。确保使用者可安心地、无干扰地关注业务功能的开发和使用 尽可能避免让他人在解决与其业务不相关的问题上耗费不必要的时间，进而减少社会总体时间成本 命名清晰且与业务意义相关，太过随意的名称或简写对阅读和理解代码将造成极大阻碍，会提高他人以及未来的自己的时间成本 通过博客等向外界阐述、解释、提供案例/代码等，务必做到简洁、清晰、流畅、准确，不要让他人再耗费比自己更长的时间来理解文章内容、判断准确性等，应力求将读者的时间成本降至最低 确保IDE具有自动版本控制功能，保证误删除代码可准确恢复 不要纠结于文档或代码格式等细节问题，首先关注其内容，格式问题需逐步引导并规范 提供完整、详细、准确的注释，并说明接口的使用方式、适用场景、注意事项等开发者需注意和其真正所关注的内容 尽可能优先编写测试用例，并在业务逻辑修改后先跑测试用例，再检查业务功能 数据库字段名、字段别名、表别名以“_”结尾，以避免和数据库关键字冲突 时间、日期以长整形进行前后端交互，避免格式化方式不同而造成的性能消耗和解析复杂 在后端统一拦截异常，并在前端针对500错误做统一显示 尽可能避免多应用、多线程共享数据或变量，应用之间操作数据需调用提供方的接口，严禁直接操作对方的数据 服务端API应支持模型的局部更新，即客户端仅向服务端发送需变更的字段及数据，未发送的字段不做变更 若SQL查询中需要限定包含二进制或文本列的数据行唯一性时，先通过子查询限定id的唯一性，再查出id在该子查询结果内的数据行 Oracle中不支持Clob/Blob等字段的distinct约束 避免在if/else中包含过长代码，可将其提取为独立接口，或者，通过return提前返回，以使分支逻辑更加清晰 在操作大量数据（以万及以上为单位）时，需尽可能避免使用递归，循环的效率比递归更高 避免使用Hibernate的级联更新，而应使用单独接口处理级联数据 尽可能为过程数据、临时数据、文件解析等创建对应的模型对象（Class），避免以Map等记录中间数据，从而保证代码的可读性，同时也有利于代码的自动化检查和处理 避免使用字符串字面量（Literal），应积极使用枚举类型来代表各类常量 将业务数据、消息数据、分析数据、日志数据等独立存储，并使用更合适的数据库或技术堆栈存储和查询 不要排斥switch/case，在很多情况下，其比if/else更优雅"},{"title":"软件开发行为准则","permalink":"https://flytreeleft.github.io/the-software-development-criterion/","text":"The post isn’t finished yet, it will be updated anytime! 谨慎对待用户隐私提要： 不是仅用户确认后的数据才算是「用户隐私」，任何与用户相关的数据都应该「默认」视为用户隐私，不需要任何形式的确认，而只有经过用户确认和同意的数据方可用作其他用途，且前提必须是明确告知数据为何要做此用途，以及将被如何利用、涉及哪些风险等 努力降低总体开发和使用成本提要： 总体成本等于所有个人的时间成本与财力物力之总和 提供到达/完成目标的最短操作路径 提供详细的文档（开发、设计、使用），备注相关知识来源链接，从最终使用者角度考虑使用流程、会遇到的困难和疑问、期望的快捷方式 将当前关注点在一页（一屏）中展示；直接到达操作按钮； 从开发者与最终用户的角度思考各个关注点，直接提供所需信息、接口、说明以及软件功能 不是一眼就明了其意义的图标需提供文字提示或说明，或者直接使用文字"},{"title":"如何突破自己的瓶颈？","permalink":"https://flytreeleft.github.io/how-to-break-out-of-your-limit/","text":"The post isn’t finished yet, it will be updated anytime! 以旁观者角度审视自己提要： 勇敢面对自己，正视自己的缺点 客观分析自己的好的、坏的甚至是邪恶的想法，不好的想法切不可影响到他人，需要自我消化 人无完人，对于非理性情绪不要过分压抑，在不影响他人的情况下采取各种积极或消极的方式去释放这些情绪 消极的释放方式所要达到的目的是推翻重建，进入全新的境界，从而从另一个视角看待原来的情绪和行为 理性看待他人的评论、观点和建议，保持就事论事的态度，切忌带有个人情绪，更不要被别人带着走（影响个人情绪、怀疑个人价值观等等）提要： 若无法静心并保持客观，那就禁用评论，不与人争论，专注于自己的思考方向，但需多接触不同观点，及时调整，不可过于执念 开放心态，放下恩怨是非，求同存异 事物的美好在于不同，不同的观点、思想的碰撞才能产生激烈的火花，而消灭差异最终只会沦为「行尸走肉」 「尊重你说话的权利，但也保留我的个人意见」 没有绝对的对错，对错都是相对的，在不同身份、不同环境、不同角度甚至可能发生反转。依据当前已知信息作出相对合理的选择，并在实践过程中不断调整 专注于探索自己的生活方式和方向，不羡慕别人的生活，先过好自己的提要： 时常在朋友圈、新闻、他人口中看到或听到某某光鲜亮丽、幸福美满、事业猛进，而自己依然处于迷茫、混沌、一人吃饱全家不饿的状态，心里倍感失落、感觉就是一loser，进而嫉妒别人，甚而诅咒他人 那你需要静下来分析，如何形成当前局面，自己真正需要的是什么，自己在生活的路上做了什么 别人都在幸福的路上忙碌奔波，而你却有如此闲心去妒嫉别人的生活？ 人人都有自己的活法，也有不同的满足，找到属于自己的，并聚焦于此，为此而忙碌，心无杂念 以“出世”的态度去观察他人和自己，不要觉得自己过得不如意就希望全世界都得与你一起面对种种不如意，从他人的不幸中去寻找优越感，将会使自己越来越失败、愤恨、怀疑自己。不断战胜、超越自己才是正途 始终保持内心的平静，避免外界对自己的诱惑和干扰，要有自己的坚守，纯粹的名与利终究是带不走的 沉下心来专注于自己的事情，朝着自己认为可行的方向前行，也许会失败，但在行进过程中同样也能学到很多东西，所以，不要一开始就因为害怕失败而不去做，先勇敢地去做，快速尝试以快速失败或成功 对所见、所听、所接触的事、物、人，取其精华去其糟泊，吸收有用可取的方式，探索本质，获得处事之道提要： 有些人就是人生路上的“小怪兽”，有些人是良师益友 随时准备两件事情，以避免当前事情完成后不知道该继续做什么的困境准备一份阅读书籍列表，在无所事事时，避免无目的的刷网页，转而看书会更加有益"},{"title":"Git使用案例","permalink":"https://flytreeleft.github.io/git-usage-cases/","text":"拆分子目录到新仓库场景通常为便于项目开发和调试，开发前期会将多个组件放在同一仓库中，而当各个组件的功能结构和代码逐渐区域稳定后，便需要将其拆分出来进行独立开发和管理，以便于与其他项目共享组件。 此时，不仅需要将组件所在目录内的代码全部拆分到单独的仓库，同时，还需要确保历史记录能够完整保留。 操作1234567891011121314151617# Clone the repository that contains the subfolder.git clone https://github.com/USERNAME/REPOSITORY-NAMEcd REPOSITORY-NAME# To filter out the subfolder from the rest of the files in the repository## FOLDER-NAME: The folder within your project that you'd like to create a separate repository from.## BRANCH-NAME: The default branch for your current project, for example, 'master' or 'gh-pages'git filter-branch --prune-empty --subdirectory-filter FOLDER-NAME BRANCH-NAME# Change the existing remote 'origin' (or other name) URL to the new repository URLgit remote set-url origin https://github.com/USERNAME/NEW-REPOSITORY-NAME.git# [Optional] Change BRANCH-NAME to the default branch (e.g. 'master') of the new repositorygit branch -m BRANCH-NAME master# Push your changes to the new repositorygit push -u origin master 注意： 在第二步操作后，当前目录将会只剩下子目录中的文件 最好在新的目录中进行上述操作：可以直接clone，也可以从复制已有项目到其他目录 参考 Splitting a subfolder out into a new repository 修改变更提交人的信息场景基于项目长远发展考虑，将某个具有实用价值且吸引力极大的项目开源，需要将项目从公司内部仓库开放到Github上，但相关开发人员在两个系统中所用帐号不一致，为了便于issue交流以及PR提交，这时，需要更改历史中的提交人信息。 其实，大多数时候，很可能是要弃用内部仓库并将工作全部移到公共仓库时才有这么做的需求，其余情况并不需要这么做。 操作 部分替换： 12345678910git filter-branch --commit-filter \\ 'if [ \"$GIT_AUTHOR_NAME\" = \"OldAuthor Name\" ]; then \\ export GIT_AUTHOR_NAME=\"Author Name\"; \\ export GIT_AUTHOR_EMAIL=authorEmail@example.com; \\ export GIT_COMMITTER_NAME=\"Commmiter Name\"; \\ export GIT_COMMITTER_EMAIL=commiterEmail@example.com; \\ fi; \\ git commit-tree \"$@\" '# Push to the branch 'master' of the existing repositorygit push --force origin master 全部替换： 12345678git filter-branch --commit-filter \\ 'export GIT_AUTHOR_NAME=\"Author Name\"; \\ export GIT_AUTHOR_EMAIL=authorEmail@example.com; \\ export GIT_COMMITTER_NAME=\"Commmiter Name\"; \\ export GIT_COMMITTER_EMAIL=commiterEmail@example.com; \\ git commit-tree \"$@\" '# Push to the branch 'master' of the existing repositorygit push --force origin master 注意： 若出现类似Cannot create a new backup. A previous backup already exists in refs/original/. Force overwriting the backup with -f的异常提示，则需要在filter-branch命令中添加选项-f，即git filter-branch -f，以强制进行修改 如果提交的分支是受保护的，则在提交时会出现remote: GitLab: You are not allowed to force push code to a protected branch on this project.的错误信息，此时，需要调整仓库设置，临时取消对目标分支的保护 参考 Could I change my name and surname in all previous commits? 迁移子分支至新仓库场景某个项目仓库中可能存在多个功能特性（features）分支，在一段时候后，基于产品功能规划和开发维护等方面的考虑，需要将某些特性分支独立成新的项目或子项目，将其迁移到新的仓库中。 操作12345678# Push 'feature-branch' to the branch 'master' (or others) of new repositorygit push url://to/new/repository.git feature-branch:master# [Optional] Delete the 'feature-branch' from current repositorygit branch -d feature-branch# Clone codes from new repositorygit clone url://to/new/repository.git feature-branch 参考 How do I move a Git branch out into its own repository? 修改历史提交备注信息场景在拆分子目录和迁移子分支两个场景中，在新仓库中的历史提交记录的备注信息可能存在与项目不相关的信息或者包含原始项目中的一些敏感内容。这个时候，就可能需要修改这些备注信息。 当然，也可能是因为发现以前的提交备注中包含错别字或者表达不清晰，为了避免对其他人产生误导或困惑，将提交的备注信息予以纠正也是很有必要的。 操作 获取提交ID并Rebase到该提交 12345# List histories and get the commit id which should be modifiedgit log# Rebase to 3 commits before the specified commit (e.g. 'ce0ac37c83')git rebase --interactive ce0ac37c83~3 将提交所在行开始处的pick修改为edit 提交并应用修改 123456789# New commit messagegit commit --amend -m \"fix that the dragging preview can not be shown\"# Apply the changes and return to HEADgit rebase --continue# Push to the branch 'master' of the existing repository## Make sure that the remote branch 'master' is unprotectedgit push --force origin master 注意： 如果需要放弃修改，则运行命令git rebase --abort 若直接rebase到目标commit，则该提交不会显示在可修改清单内，故，需选择从其之前的第N个（e.g. ~3）提交开始 若提交至非空的仓库，需确保目标分支不是受保护（protected）的 在应用修改后，git将从修改位置开始重新构建commit tree，因此，从该位置开始到HEAD的commit id均会发生变化，但原始commit tree依然存在，通过git diff ce0ac37c83等可看到该提交的变更情况 参考 How to modify existing, unpushed commits?"},{"title":"Hello world!","permalink":"https://flytreeleft.github.io/hello-world/","text":"1System.out.println(\"Hello world!\"); 1alert('Hello world!'); 1echo \"Hello world!\""}]}